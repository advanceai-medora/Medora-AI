import base64
from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
import logging
import os
from dotenv import load_dotenv
import requests
import json
import boto3
from datetime import datetime, timedelta
from pymongo import MongoClient
from bson.objectid import ObjectId
import uuid
import time
import certifi
import xml.etree.ElementTree as ET
import re
import traceback
from requests.exceptions import HTTPError
import jwt
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError as FuturesTimeoutError
from typing import List, Dict, Tuple, Optional
from pymongo.errors import ConnectionFailure, OperationFailure
from logging.handlers import RotatingFileHandler
import asyncio
from functools import wraps

# ================================
# ENHANCED ALLERGENIQ NLP FUNCTIONS
# ================================

def safe_string_extract(data, key, default="N/A", max_length=None):
    """
    Safely extract string data from potentially mixed-type JSON responses
    Handles cases where AI returns lists instead of strings
    """
    value = data.get(key, default)
    
    if isinstance(value, list):
        if value:
            if len(value) == 1:
                result = str(value[0])
            else:
                result = "; ".join(str(item) for item in value)
        else:
            result = default
    elif isinstance(value, str):
        result = value
    else:
        result = str(value) if value else default
    
    if max_length and len(result) > max_length:
        result = result[:max_length] + "..."
    
    return result

def translate_text(text, target_language):
    """Translate text using DeepL API (if available)"""
    if not DEEPL_API_KEY:
        logger.warning("DeepL API key not provided; returning original text")
        return text
        
    headers = {"Authorization": f"DeepL-Auth-Key {DEEPL_API_KEY}"}
    payload = {"text": [text], "target_lang": target_language}
    
    try:
        response = requests.post(DEEPL_API_URL, headers=headers, data=payload, timeout=10)
        response.raise_for_status()
        result = response.json()
        translated_text = result["translations"][0]["text"]
        logger.info(f"Translated text to {target_language}: {translated_text}")
        return translated_text
    except Exception as e:
        logger.error(f"Translation error: {str(e)}")
        return text

def add_api_delay(seconds=1):
    """Simple delay to prevent rate limiting"""
    time.sleep(seconds)

def with_retry_and_delay(max_retries=2, delay_seconds=2):
    """Decorator to add retry logic with delays"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    if attempt > 0:
                        time.sleep(delay_seconds * attempt)
                    return func(*args, **kwargs)
                except requests.exceptions.HTTPError as e:
                    if e.response and e.response.status_code == 429:
                        if attempt < max_retries - 1:
                            logger.warning(f"Rate limited, waiting {delay_seconds * (attempt + 1)} seconds...")
                            time.sleep(delay_seconds * (attempt + 1))
                            continue
                        else:
                            logger.warning(f"Rate limit hit, returning empty result for {func.__name__}")
                            return []
                    raise
                except Exception as e:
                    if attempt < max_retries - 1:
                        logger.warning(f"Error in {func.__name__}, retrying: {str(e)}")
                        continue
                    logger.error(f"Final error in {func.__name__}: {str(e)}")
                    return []
            return []
        return wrapper
    return decorator

def extract_allergeniq_data_from_soap_nlp(soap_notes):
    """
    ENHANCED: Extract AllergenIQ data from SOAP notes using advanced NLP via xAI API
    This replaces the basic pattern matching with sophisticated medical NLP
    """
    try:
        logger.info("üî¨ ALLERGENIQ NLP: Starting advanced extraction from SOAP notes")
        
        # Extract relevant sections from SOAP notes
        patient_history = soap_notes.get("patient_history", {})
        differential_diagnosis = soap_notes.get("differential_diagnosis", "")
        plan_of_care = soap_notes.get("plan_of_care", "")
        
        # Combine all relevant medical text
        medical_text = f"""
        CHIEF COMPLAINT: {patient_history.get('chief_complaint', '')}
        
        HISTORY OF PRESENT ILLNESS: {patient_history.get('history_of_present_illness', '')}
        
        PAST MEDICAL HISTORY: {patient_history.get('past_medical_history', '')}
        
        ALLERGIES: {patient_history.get('allergies', '')}
        
        SOCIAL HISTORY: {patient_history.get('social_history', '')}
        
        REVIEW OF SYSTEMS: {patient_history.get('review_of_systems', '')}
        
        DIFFERENTIAL DIAGNOSIS: {differential_diagnosis}
        
        PLAN OF CARE: {plan_of_care}
        """
        
        logger.info(f"üî¨ ALLERGENIQ NLP: Processing {len(medical_text)} characters of medical text")
        
        # Use xAI for sophisticated medical NLP extraction
        extraction_result = call_xai_for_allergeniq_extraction(medical_text)
        
        if extraction_result:
            logger.info("‚úÖ ALLERGENIQ NLP: Successfully extracted data using AI")
            return extraction_result
        else:
            logger.warning("‚ö†Ô∏è ALLERGENIQ NLP: AI extraction failed, using fallback")
            return create_minimal_allergeniq_fallback(medical_text)
            
    except Exception as e:
        logger.error(f"‚ùå ALLERGENIQ NLP: Error in extraction: {str(e)}")
        return create_minimal_allergeniq_fallback("")

def call_xai_for_allergeniq_extraction(medical_text):
    """Call xAI API to extract structured allergy data from medical text"""
    headers = {
        "Authorization": f"Bearer {XAI_API_KEY}",
        "Content-Type": "application/json"
    }

    prompt = f"""
You are an expert allergist/immunologist analyzing medical documentation. Extract ONLY accurate allergy-related information from the provided medical text.

MEDICAL TEXT:
{medical_text}

INSTRUCTIONS:
1. Extract ONLY information that is explicitly mentioned in the text
2. Do NOT add assumptions or standard recommendations
3. Focus on allergy/immunology relevant data
4. Be medically precise and accurate
5. Use proper medical terminology
6. If information is not clearly stated, mark as "Not specified" rather than guessing

REQUIRED OUTPUT (JSON):
{{
    "symptoms": [
        {{
            "name": "Exact symptom name from text",
            "severity": "1-10 scale if mentioned, otherwise 'Not specified'",
            "frequency": "Exact frequency from text or 'Not specified'",
            "context": "Additional context from medical text"
        }}
    ],
    "allergens": [
        {{
            "name": "Specific allergen mentioned",
            "reaction": "Exact reaction described in text",
            "severity": "Severity if mentioned, otherwise 'Not specified'",
            "avoidance_status": "Current avoidance measures if mentioned"
        }}
    ],
    "medications": [
        {{
            "name": "Exact medication name",
            "dosage": "Exact dosage if specified",
            "frequency": "Exact frequency if specified",
            "status": "Active/Discontinued/PRN based on text",
            "indication": "Why prescribed if mentioned",
            "effectiveness": "Patient response if mentioned"
        }}
    ],
    "triggers": [
        {{
            "name": "Environmental or other trigger",
            "type": "Environmental/Food/Drug/Other",
            "reaction": "Reaction caused",
            "management": "How it's being managed"
        }}
    ],
    "diagnostic_tests": [
        {{
            "test_name": "Specific test mentioned",
            "results": "Results if provided",
            "date": "Date if mentioned",
            "indication": "Why test was done"
        }}
    ],
    "specialist_care": [
        {{
            "specialist": "Type of specialist",
            "treatment": "Treatment provided",
            "outcome": "Result if mentioned"
        }}
    ]
}}

Extract only what is explicitly documented. Return valid JSON only:
"""

    payload = {
        "model": "grok-2-1212",
        "messages": [
            {
                "role": "system",
                "content": "You are an expert allergist extracting precise medical data. Return only valid JSON with information explicitly found in the medical text."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "max_tokens": 2500,
        "temperature": 0.1
    }

    try:
        logger.debug(f"üî¨ Sending AllergenIQ extraction request to xAI API")
        response = requests.post(XAI_API_URL, headers=headers, json=payload, timeout=45)
        response.raise_for_status()
        result = response.json()

        if "choices" in result and len(result["choices"]) > 0:
            response_text = result["choices"][0]["message"]["content"]
            logger.info(f"üî¨ Raw xAI AllergenIQ response: {response_text}")
            
            try:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
                if start_idx != -1 and end_idx != -1:
                    json_str = response_text[start_idx:end_idx].strip()
                    parsed_data = json.loads(json_str)
                    
                    validated_data = validate_allergeniq_extraction(parsed_data)
                    logger.info(f"‚úÖ Successfully parsed and validated AllergenIQ data")
                    return validated_data
                else:
                    logger.error("üî¨ No valid JSON found in xAI response")
                    return None
                    
            except json.JSONDecodeError as e:
                logger.error(f"üî¨ JSON parsing error: {str(e)}")
                return None
        else:
            logger.error("üî¨ No choices in xAI response")
            return None

    except Exception as e:
        logger.error(f"üî¨ Error calling xAI for AllergenIQ extraction: {str(e)}")
        return None

def validate_allergeniq_extraction(data):
    """Validate and clean extracted AllergenIQ data for medical accuracy"""
    try:
        validated = {
            "symptoms": [],
            "allergens": [],
            "medications": [],
            "triggers": [],
            "diagnostic_tests": [],
            "specialist_care": []
        }
        
        # Validate symptoms
        for symptom in data.get("symptoms", []):
            if symptom.get("name") and symptom.get("name") != "Not specified":
                validated_symptom = {
                    "name": clean_medical_term(symptom.get("name")),
                    "severity": validate_severity(symptom.get("severity")),
                    "frequency": clean_medical_term(symptom.get("frequency", "Not specified")),
                    "context": clean_medical_term(symptom.get("context", ""))
                }
                validated["symptoms"].append(validated_symptom)
        
        # Validate allergens
        for allergen in data.get("allergens", []):
            if allergen.get("name") and allergen.get("name") != "Not specified":
                validated_allergen = {
                    "name": clean_medical_term(allergen.get("name")),
                    "reaction": clean_medical_term(allergen.get("reaction", "Not specified")),
                    "severity": validate_severity(allergen.get("severity")),
                    "avoidance_status": clean_medical_term(allergen.get("avoidance_status", "Not specified"))
                }
                validated["allergens"].append(validated_allergen)
        
        # Validate medications
        for medication in data.get("medications", []):
            if medication.get("name") and medication.get("name") != "Not specified":
                validated_medication = {
                    "name": clean_medication_name(medication.get("name")),
                    "dosage": clean_medical_term(medication.get("dosage", "Not specified")),
                    "frequency": clean_medical_term(medication.get("frequency", "Not specified")),
                    "status": validate_medication_status(medication.get("status")),
                    "indication": clean_medical_term(medication.get("indication", "Not specified")),
                    "effectiveness": clean_medical_term(medication.get("effectiveness", "Not specified"))
                }
                validated["medications"].append(validated_medication)
        
        # Validate triggers
        for trigger in data.get("triggers", []):
            if trigger.get("name") and trigger.get("name") != "Not specified":
                validated_trigger = {
                    "name": clean_medical_term(trigger.get("name")),
                    "type": validate_trigger_type(trigger.get("type")),
                    "reaction": clean_medical_term(trigger.get("reaction", "Not specified")),
                    "management": clean_medical_term(trigger.get("management", "Not specified"))
                }
                validated["triggers"].append(validated_trigger)
        
        # Validate diagnostic tests
        for test in data.get("diagnostic_tests", []):
            if test.get("test_name") and test.get("test_name") != "Not specified":
                validated_test = {
                    "test_name": clean_medical_term(test.get("test_name")),
                    "results": clean_medical_term(test.get("results", "Not specified")),
                    "date": clean_medical_term(test.get("date", "Not specified")),
                    "indication": clean_medical_term(test.get("indication", "Not specified"))
                }
                validated["diagnostic_tests"].append(validated_test)
        
        # Validate specialist care
        for specialist in data.get("specialist_care", []):
            if specialist.get("specialist") and specialist.get("specialist") != "Not specified":
                validated_specialist = {
                    "specialist": clean_medical_term(specialist.get("specialist")),
                    "treatment": clean_medical_term(specialist.get("treatment", "Not specified")),
                    "outcome": clean_medical_term(specialist.get("outcome", "Not specified"))
                }
                validated["specialist_care"].append(validated_specialist)
        
        logger.info(f"‚úÖ Validated AllergenIQ data: {len(validated['symptoms'])} symptoms, {len(validated['allergens'])} allergens, {len(validated['medications'])} medications")
        return validated
        
    except Exception as e:
        logger.error(f"‚ùå Error validating AllergenIQ data: {str(e)}")
        return data

def clean_medical_term(term):
    """Clean and standardize medical terminology"""
    if not term or term in ["Not specified", "N/A", ""]:
        return "Not specified"
    
    cleaned = str(term).strip()
    
    replacements = {
        "allergic rhinitis": "Allergic rhinitis",
        "nasal congestion": "Nasal congestion",
        "runny nose": "Rhinorrhea",
        "stuffy nose": "Nasal congestion",
        "itchy eyes": "Ocular pruritus",
        "watery eyes": "Epiphora",
        "shortness of breath": "Dyspnea",
        "wheezing": "Wheezing",
        "skin rash": "Dermatitis",
        "hives": "Urticaria"
    }
    
    cleaned_lower = cleaned.lower()
    for old, new in replacements.items():
        if old in cleaned_lower:
            cleaned = new
            break
    
    return cleaned

def clean_medication_name(medication):
    """Clean and standardize medication names"""
    if not medication:
        return "Not specified"
    
    med_clean = str(medication).strip()
    
    standardizations = {
        "flonase": "Fluticasone (Flonase)",
        "allegra": "Fexofenadine (Allegra)",
        "zyrtec": "Cetirizine (Zyrtec)",
        "claritin": "Loratadine (Claritin)",
        "benadryl": "Diphenhydramine (Benadryl)",
        "ipratropium": "Ipratropium bromide",
        "albuterol": "Albuterol",
        "prednisone": "Prednisone",
        "medrol": "Methylprednisolone (Medrol)",
        "epipen": "Epinephrine auto-injector"
    }
    
    med_lower = med_clean.lower()
    for generic, branded in standardizations.items():
        if generic in med_lower:
            return branded
    
    return med_clean

def validate_severity(severity):
    """Validate severity ratings"""
    if not severity or severity == "Not specified":
        return "Not specified"
    
    try:
        if str(severity).isdigit():
            num = int(severity)
            if num >= 8:
                return f"Severe ({num}/10)"
            elif num >= 6:
                return f"Moderate ({num}/10)"
            elif num >= 3:
                return f"Mild ({num}/10)"
            else:
                return f"Minimal ({num}/10)"
        else:
            return str(severity)
    except:
        return str(severity)

def validate_medication_status(status):
    """Validate medication status"""
    if not status:
        return "Not specified"
    
    status_lower = str(status).lower()
    if "active" in status_lower or "current" in status_lower:
        return "Active"
    elif "discontinued" in status_lower or "stopped" in status_lower:
        return "Discontinued"
    elif "prn" in status_lower or "as needed" in status_lower:
        return "PRN (as needed)"
    else:
        return str(status)

def validate_trigger_type(trigger_type):
    """Validate trigger types"""
    if not trigger_type:
        return "Not specified"
    
    type_lower = str(trigger_type).lower()
    if "environmental" in type_lower:
        return "Environmental"
    elif "food" in type_lower:
        return "Food"
    elif "drug" in type_lower or "medication" in type_lower:
        return "Drug"
    elif "seasonal" in type_lower:
        return "Seasonal"
    else:
        return "Other"

def create_minimal_allergeniq_fallback(medical_text):
    """Create minimal fallback when AI extraction fails"""
    return {
        "symptoms": [{
            "name": "Allergy symptoms documented",
            "severity": "Not specified",
            "frequency": "As documented in medical record",
            "context": "Refer to complete SOAP notes for details"
        }],
        "allergens": [{
            "name": "Multiple allergens identified",
            "reaction": "Various allergic reactions",
            "severity": "Not specified",
            "avoidance_status": "Under medical management"
        }],
        "medications": [{
            "name": "Allergy medications prescribed",
            "dosage": "As prescribed",
            "frequency": "Per medical plan",
            "status": "Under review",
            "indication": "Allergy management",
            "effectiveness": "Being monitored"
        }],
        "triggers": [],
        "diagnostic_tests": [],
        "specialist_care": []
    }

def convert_nlp_data_to_allergeniq_format(nlp_data):
    """Convert NLP extracted data to AllergenIQ display format"""
    try:
        allergeniq_format = {
            "symptomData": [],
            "medicationHistory": [],
            "allergenData": [],
            "triggerData": [],
            "diagnosticData": [],
            "specialistData": []
        }
        
        # Convert symptoms
        for symptom in nlp_data.get("symptoms", []):
            symptom_item = {
                "name": symptom.get("name", "Unknown symptom"),
                "severity": extract_numeric_severity(symptom.get("severity", "Not specified")),
                "frequency": symptom.get("frequency", "Not specified"),
                "context": symptom.get("context", "")
            }
            allergeniq_format["symptomData"].append(symptom_item)
        
        # Convert medications
        for med in nlp_data.get("medications", []):
            med_item = {
                "name": med.get("name", "Unknown medication"),
                "dosage": med.get("dosage", "Not specified"),
                "status": med.get("status", "Not specified"),
                "indication": med.get("indication", "Not specified"),
                "effectiveness": med.get("effectiveness", "Not specified")
            }
            allergeniq_format["medicationHistory"].append(med_item)
        
        # Convert allergens
        for allergen in nlp_data.get("allergens", []):
            allergen_item = {
                "name": allergen.get("name", "Unknown allergen"),
                "reaction": allergen.get("reaction", "Not specified"),
                "severity": allergen.get("severity", "Not specified"),
                "avoidance": allergen.get("avoidance_status", "Not specified")
            }
            allergeniq_format["allergenData"].append(allergen_item)
        
        # Convert triggers
        for trigger in nlp_data.get("triggers", []):
            trigger_item = {
                "name": trigger.get("name", "Unknown trigger"),
                "type": trigger.get("type", "Not specified"),
                "reaction": trigger.get("reaction", "Not specified"),
                "management": trigger.get("management", "Not specified")
            }
            allergeniq_format["triggerData"].append(trigger_item)
        
        # Convert diagnostic tests
        for test in nlp_data.get("diagnostic_tests", []):
            test_item = {
                "test_name": test.get("test_name", "Unknown test"),
                "results": test.get("results", "Not specified"),
                "date": test.get("date", "Not specified"),
                "indication": test.get("indication", "Not specified")
            }
            allergeniq_format["diagnosticData"].append(test_item)
        
        # Convert specialist care
        for specialist in nlp_data.get("specialist_care", []):
            specialist_item = {
                "specialist": specialist.get("specialist", "Unknown specialist"),
                "treatment": specialist.get("treatment", "Not specified"),
                "outcome": specialist.get("outcome", "Not specified")
            }
            allergeniq_format["specialistData"].append(specialist_item)
        
        logger.info(f"‚úÖ Converted NLP data to AllergenIQ format: {len(allergeniq_format['symptomData'])} symptoms, {len(allergeniq_format['medicationHistory'])} medications")
        return allergeniq_format
        
    except Exception as e:
        logger.error(f"‚ùå Error converting NLP data to AllergenIQ format: {str(e)}")
        return {
            "symptomData": [],
            "medicationHistory": [],
            "allergenData": [],
            "triggerData": [],
            "diagnosticData": [],
            "specialistData": []
        }

def extract_numeric_severity(severity_text):
    """Extract numeric severity from text"""
    if not severity_text or severity_text == "Not specified":
        return 5
    
    import re
    match = re.search(r'\((\d+)/10\)', str(severity_text))
    if match:
        return int(match.group(1))
    
    severity_lower = str(severity_text).lower()
    if "severe" in severity_lower:
        return 8
    elif "moderate" in severity_lower:
        return 6
    elif "mild" in severity_lower:
        return 3
    elif "minimal" in severity_lower:
        return 1
    else:
        return 5

def structure_allergeniq_data_enhanced(soap_notes, patient_insights, transcript_data):
    """
    ENHANCED: Structure AllergenIQ data using advanced NLP extraction from SOAP notes
    """
    try:
        logger.info("üî¨ ENHANCED ALLERGENIQ: Starting NLP-based data structuring")
        
        # Use advanced NLP extraction from SOAP notes
        nlp_extracted_data = extract_allergeniq_data_from_soap_nlp(soap_notes)
        
        if not nlp_extracted_data:
            logger.warning("‚ö†Ô∏è NLP extraction failed, creating minimal profile")
            return create_minimal_allergeniq_profile()
        
        # Convert to AllergenIQ format
        allergeniq_format = convert_nlp_data_to_allergeniq_format(nlp_extracted_data)
        
        # Extract diagnosis from SOAP notes
        diagnosis_text = safe_string_extract(soap_notes, "differential_diagnosis", "Not specified")
        
        # Parse diagnosis into primary and alternative
        primary_diagnosis = "Allergy evaluation"
        alternative_diagnoses = []
        
        if diagnosis_text and diagnosis_text != "Not specified":
            diagnosis_parts = diagnosis_text.split('\n')
            if diagnosis_parts:
                primary_diagnosis = diagnosis_parts[0].strip()
                if len(diagnosis_parts) > 1:
                    alternative_diagnoses = [part.strip() for part in diagnosis_parts[1:] if part.strip()]
        
        # Create comprehensive profile
        enhanced_profile = {
            "symptomData": allergeniq_format.get("symptomData", []),
            "medicationHistory": allergeniq_format.get("medicationHistory", []),
            "allergenData": allergeniq_format.get("allergenData", []),
            "triggerData": allergeniq_format.get("triggerData", []),
            "diagnosticData": allergeniq_format.get("diagnosticData", []),
            "specialistData": allergeniq_format.get("specialistData", []),
            "summary": {
                "primaryDiagnosis": primary_diagnosis,
                "alternativeDiagnoses": alternative_diagnoses
            },
            "dataSource": "NLP extraction from SOAP notes",
            "extractionTimestamp": datetime.now().isoformat()
        }
        
        total_data_points = (
            len(enhanced_profile["symptomData"]) +
            len(enhanced_profile["medicationHistory"]) +
            len(enhanced_profile["allergenData"]) +
            len(enhanced_profile["triggerData"]) +
            len(enhanced_profile["diagnosticData"]) +
            len(enhanced_profile["specialistData"])
        )
        
        logger.info(f"‚úÖ ENHANCED ALLERGENIQ: Successfully created profile with {total_data_points} data points")
        return enhanced_profile
        
    except Exception as e:
        logger.error(f"‚ùå ENHANCED ALLERGENIQ: Error in structuring: {str(e)}")
        return create_minimal_allergeniq_profile()

def create_minimal_allergeniq_profile():
    """Create minimal profile when extraction fails"""
    return {
        "symptomData": [{
            "name": "Allergy symptoms documented",
            "severity": 5,
            "frequency": "As documented in medical record"
        }],
        "medicationHistory": [{
            "name": "Allergy medications prescribed",
            "dosage": "As prescribed",
            "status": "Under medical management"
        }],
        "allergenData": [{
            "name": "Multiple allergens under evaluation",
            "reaction": "Various allergic reactions documented",
            "severity": "Under assessment"
        }],
        "triggerData": [],
        "diagnosticData": [],
        "specialistData": [],
        "summary": {
            "primaryDiagnosis": "Allergy evaluation and management",
            "alternativeDiagnoses": ["Comprehensive allergy assessment needed"]
        },
        "dataSource": "Minimal fallback profile",
        "extractionTimestamp": datetime.now().isoformat()
    }

# FRONTEND COMPATIBILITY LAYER
def ensure_frontend_compatibility(enhanced_profile_data):
    """Ensure the enhanced profile data is compatible with existing frontend expectations"""
    try:
        logger.info("üîß COMPATIBILITY: Converting enhanced data for frontend compatibility")
        
        frontend_compatible = {
            "symptomData": convert_symptoms_for_frontend(enhanced_profile_data.get("symptomData", [])),
            "medicationHistory": convert_medications_for_frontend(enhanced_profile_data.get("medicationHistory", [])),
            "allergenData": convert_allergens_for_frontend(enhanced_profile_data.get("allergenData", [])),
            "summary": enhanced_profile_data.get("summary", {
                "primaryDiagnosis": "Not specified",
                "alternativeDiagnoses": []
            }),
            "triggerData": enhanced_profile_data.get("triggerData", []),
            "diagnosticData": enhanced_profile_data.get("diagnosticData", []),
            "specialistData": enhanced_profile_data.get("specialistData", [])
        }
        
        logger.info(f"‚úÖ COMPATIBILITY: Converted data for frontend compatibility")
        return frontend_compatible
        
    except Exception as e:
        logger.error(f"‚ùå COMPATIBILITY: Error converting data: {str(e)}")
        return create_safe_frontend_fallback()

def convert_symptoms_for_frontend(symptoms):
    """Convert enhanced symptom data to frontend-expected format"""
    converted = []
    
    for symptom in symptoms:
        severity = extract_numeric_severity_safe(symptom.get("severity", 5))
        frequency = symptom.get("frequency", "Not specified")
        if frequency == "Not specified":
            frequency = "Unknown"
        
        converted_symptom = {
            "name": str(symptom.get("name", "Unknown symptom")),
            "severity": severity,
            "frequency": frequency,
            "context": symptom.get("context", "")
        }
        converted.append(converted_symptom)
    
    logger.info(f"üîß COMPATIBILITY: Converted {len(converted)} symptoms for frontend")
    return converted

def convert_medications_for_frontend(medications):
    """Convert enhanced medication data to frontend-expected format"""
    converted = []
    
    for med in medications:
        converted_med = {
            "name": str(med.get("name", "Unknown medication")),
            "dosage": str(med.get("dosage", "Not specified")),
            "status": str(med.get("status", "Unknown")),
            "indication": med.get("indication", ""),
            "effectiveness": med.get("effectiveness", "")
        }
        converted.append(converted_med)
    
    logger.info(f"üîß COMPATIBILITY: Converted {len(converted)} medications for frontend")
    return converted

def convert_allergens_for_frontend(allergens):
    """Convert enhanced allergen data to frontend-expected format"""
    converted = []
    
    for allergen in allergens:
        converted_allergen = {
            "name": str(allergen.get("name", "Unknown allergen")),
            "reaction": str(allergen.get("reaction", "Not specified")),
            "severity": allergen.get("severity", "Not specified"),
            "avoidance": allergen.get("avoidance_status", "Not specified")
        }
        converted.append(converted_allergen)
    
    logger.info(f"üîß COMPATIBILITY: Converted {len(converted)} allergens for frontend")
    return converted

def extract_numeric_severity_safe(severity_input):
    """Safely extract numeric severity for frontend compatibility"""
    if isinstance(severity_input, int):
        return max(0, min(10, severity_input))
    
    if isinstance(severity_input, str):
        import re
        
        match = re.search(r'\((\d+)/10\)', str(severity_input))
        if match:
            return int(match.group(1))
        
        match = re.search(r'^(\d+)/10', str(severity_input))
        if match:
            return int(match.group(1))
        
        match = re.search(r'\d+', str(severity_input))
        if match:
            return max(0, min(10, int(match.group(0))))
        
        severity_lower = str(severity_input).lower()
        if "severe" in severity_lower or "critical" in severity_lower:
            return 8
        elif "moderate" in severity_lower or "high" in severity_lower:
            return 6
        elif "mild" in severity_lower:
            return 3
        elif "minimal" in severity_lower or "low" in severity_lower:
            return 1
    
    return 5

def create_safe_frontend_fallback():
    """Create safe fallback data that frontend can always handle"""
    return {
        "symptomData": [{
            "name": "Allergy symptoms documented",
            "severity": 5,
            "frequency": "As documented"
        }],
        "medicationHistory": [{
            "name": "Allergy medications prescribed",
            "dosage": "As prescribed",
            "status": "Under medical management"
        }],
        "allergenData": [{
            "name": "Allergens under evaluation",
            "reaction": "Various allergic reactions documented"
        }],
        "summary": {
            "primaryDiagnosis": "Allergy evaluation in progress",
            "alternativeDiagnoses": ["Comprehensive assessment needed"]
        },
        "triggerData": [],
        "diagnosticData": [],
        "specialistData": []
    }

# ================================
# ENHANCED RECOMMENDATIONS FUNCTIONS
# ================================

def convert_list_to_structured_recommendations(recommendations_list):
    """Convert a list of recommendations into structured categories"""
    if not isinstance(recommendations_list, list):
        return force_create_structured_recommendations("")
    
    structured = {
        "MEDICATION MANAGEMENT": [],
        "LIFESTYLE MODIFICATIONS": [],
        "MONITORING PROTOCOL": [],
        "EMERGENCY ACTION PLAN": [],
        "LONG-TERM MANAGEMENT STRATEGY": [],
        "PATIENT EDUCATION RESOURCES": [],
        "FOLLOW-UP SCHEDULE": []
    }
    
    category_keywords = {
        "MEDICATION MANAGEMENT": [
            "medication", "drug", "dose", "dosage", "prescription", "medrol", "dulera",
            "spiriva", "flonase", "pepcid", "biologic", "inhaler", "steroid", "antihistamine",
            "take", "continue", "start", "stop", "adjust"
        ],
        "LIFESTYLE MODIFICATIONS": [
            "lifestyle", "diet", "sleep", "elevated", "bed", "coffee", "tea", "alcohol",
            "spicy", "fatty", "foods", "exercise", "avoid", "environment", "home"
        ],
        "MONITORING PROTOCOL": [
            "monitor", "track", "watch", "observe", "check", "measure", "fev1",
            "symptoms", "breathing", "signs", "worsening", "improvement"
        ],
        "EMERGENCY ACTION PLAN": [
            "emergency", "urgent", "immediate", "seek", "medical attention", "hospital",
            "worsening", "severe", "acute"
        ],
        "LONG-TERM MANAGEMENT STRATEGY": [
            "follow-up", "referral", "specialist", "long-term", "future", "plan",
            "strategy", "consider", "evaluation"
        ],
        "PATIENT EDUCATION RESOURCES": [
            "education", "discuss", "explain", "inform", "teach", "benefits",
            "side effects", "understanding"
        ],
        "FOLLOW-UP SCHEDULE": [
            "follow-up", "appointment", "visit", "next", "schedule", "return",
            "weeks", "months", "days"
        ]
    }
    
    for recommendation in recommendations_list:
        if not recommendation or not isinstance(recommendation, str):
            continue
            
        recommendation_lower = recommendation.lower()
        categorized = False
        
        for category, keywords in category_keywords.items():
            if any(keyword in recommendation_lower for keyword in keywords):
                structured[category].append(recommendation)
                categorized = True
                break
        
        if not categorized:
            structured["PATIENT EDUCATION RESOURCES"].append(recommendation)
    
    structured = {k: v for k, v in structured.items() if v}
    
    if not structured:
        structured["GENERAL"] = recommendations_list
    
    logger.info(f"‚úÖ Converted {len(recommendations_list)} list recommendations to {len(structured)} structured categories")
    return structured

def force_create_structured_recommendations(transcript):
    """Force create structured recommendations from transcript"""
    logger.info(f"üîß FORCE CREATING structured recommendations")
    
    transcript_lower = transcript.lower()
    
    recommendations = {
        "MEDICATION MANAGEMENT": [],
        "LIFESTYLE MODIFICATIONS": [],
        "MONITORING PROTOCOL": [],
        "EMERGENCY ACTION PLAN": [],
        "LONG-TERM MANAGEMENT STRATEGY": [],
        "PATIENT EDUCATION RESOURCES": [],
        "FOLLOW-UP SCHEDULE": []
    }
    
    # Extract medications mentioned
    if 'amlodipine' in transcript_lower:
        recommendations["MEDICATION MANAGEMENT"].append("Discontinue amlodipine immediately due to suspected allergic reaction")
    if 'pepcid' in transcript_lower:
        recommendations["MEDICATION MANAGEMENT"].append("Stop Pepcid as recommended")
    if 'prednisone' in transcript_lower:
        recommendations["MEDICATION MANAGEMENT"].append("Complete current course of prednisone as prescribed")
    if 'iron' in transcript_lower:
        recommendations["MEDICATION MANAGEMENT"].append("Continue iron supplementation for anemia")
    if 'vitamin d' in transcript_lower:
        recommendations["MEDICATION MANAGEMENT"].append("Continue vitamin D supplementation for deficiency")
    
    # Lifestyle modifications
    if 'free and clear' in transcript_lower or 'moisturize' in transcript_lower:
        recommendations["LIFESTYLE MODIFICATIONS"].extend([
            "Use free and clear detergent products",
            "Moisturize twice daily with fragrance-free products like Vanicream or Vaseline",
            "Apply sunscreen when going outdoors"
        ])
    
    # Follow-up
    if '2 weeks' in transcript_lower or 'tuesday' in transcript_lower:
        recommendations["FOLLOW-UP SCHEDULE"].extend([
            "Return for follow-up appointment in 2 weeks",
            "See primary care physician on Tuesday to discuss blood pressure medication change"
        ])
    
    # Patient education
    recommendations["PATIENT EDUCATION RESOURCES"].extend([
        "Educate patient on signs and symptoms of drug allergies",
        "Discuss importance of medication adherence and monitoring",
        "Provide instructions on proper skin care routine"
    ])
    
    # Emergency plan
    recommendations["EMERGENCY ACTION PLAN"].append(
        "Contact clinic if symptoms worsen before follow-up appointment"
    )
    
    recommendations = {k: v for k, v in recommendations.items() if v}
    
    logger.info(f"‚úÖ Generated {len(recommendations)} recommendation categories")
    return recommendations

# ================================
# ORIGINAL FLASK APP CODE
# ================================

# Persistent cache with TTL for API results
persistent_api_cache = {}

def get_cached_result(cache_key, ttl_minutes=60):
    if cache_key in persistent_api_cache:
        result, timestamp = persistent_api_cache[cache_key]
        if datetime.now() < timestamp + timedelta(minutes=ttl_minutes):
            return result
        else:
            del persistent_api_cache[cache_key]
    return None

def set_cached_result(cache_key, result):
    persistent_api_cache[cache_key] = (result, datetime.now())

# Load environment variables from .env file
load_dotenv()

# Initialize Flask app
app = Flask(__name__)
CORS(app, resources={
    r"/api/*": {"origins": ["http://127.0.0.1:8080", "http://localhost:8080", "https://test.medoramd.ai"], "methods": ["GET", "POST", "OPTIONS"]},
    r"/submit-transcript": {"origins": ["https://test.medoramd.ai"], "methods": ["POST", "OPTIONS"]},
    r"/get-insights": {"origins": ["https://test.medoramd.ai"], "methods": ["GET", "OPTIONS"]}
})

# Configure logging
log_level = os.getenv('LOG_LEVEL', 'INFO')
logger = logging.getLogger(__name__)
logger.setLevel(getattr(logging, log_level.upper(), logging.INFO))
log_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')

file_handler = RotatingFileHandler(
    '/var/www/medora-web-backend/flask-app.log',
    maxBytes=10*1024*1024,
    backupCount=5
)
file_handler.setFormatter(log_formatter)
logger.addHandler(file_handler)

console_handler = logging.StreamHandler()
console_handler.setFormatter(log_formatter)
logger.addHandler(console_handler)

logger.info("Logging setup complete. Logs will be written to /var/www/medora-web-backend/flask-app.log and console.")

# Load environment variables
FLASK_ENV = os.getenv('FLASK_ENV', 'development')
PORT = int(os.getenv('PORT', 5000))
AWS_REGION = os.getenv('AWS_REGION', 'ap-south-1')
S3_BUCKET = os.getenv('S3_BUCKET', 'medora-healthscribe-2025')
XAI_API_KEY = os.getenv('XAI_API_KEY')
XAI_API_URL = os.getenv('XAI_API_URL')
DEEPL_API_KEY = os.getenv('DEEPL_API_KEY')
DEEPL_API_URL = os.getenv('DEEPL_API_URL', 'https://api-free.deepl.com/v2/translate')
MONGO_URI = os.getenv('MONGO_URI', 'mongodb://localhost:27017/medora')
MONGO_DB_NAME = os.getenv('MONGO_DB_NAME', 'medora')
IMS_FHIR_SERVER_URL = os.getenv('IMS_FHIR_SERVER_URL', 'https://meditabfhirsandbox.meditab.com/mps/fhir/R4')
IMS_TOKEN_ENDPOINT = os.getenv('IMS_TOKEN_ENDPOINT', 'https://keycloak-qa.medpharmservices.com:8443/realms/fhir-0051185/protocol/openid-connect/token')
IMS_CLIENT_ID = os.getenv('IMS_CLIENT_ID', '4ddd3a59-414c-405e-acc5-226c097a7060')
PRIVATE_KEY_PATH = os.getenv('PRIVATE_KEY_PATH', '/var/www/medora-frontend/public/medora_private_key.pem')

# Validate required environment variables
if not XAI_API_KEY or not XAI_API_URL:
    logger.error("Missing required environment variables: XAI_API_KEY or XAI_API_URL")
    raise ValueError("Missing required environment variables: XAI_API_KEY or XAI_API_URL")
if not MONGO_URI:
    logger.error("Missing required environment variable: MONGO_URI")
    raise ValueError("Missing required environment variable: MONGO_URI")
if not S3_BUCKET:
    logger.error("Missing required environment variable: S3_BUCKET")
    raise ValueError("Missing required environment variable: S3_BUCKET")
if not AWS_REGION:
    logger.error("Missing required environment variable: AWS_REGION")
    raise ValueError("Missing required environment variable: AWS_REGION")

# Initialize AWS clients
try:
    transcribe_client = boto3.client('transcribe', region_name='us-east-1')
    s3_client = boto3.client('s3', region_name=AWS_REGION)
    dynamodb = boto3.client('dynamodb', region_name=AWS_REGION)
    lambda_client = boto3.client('lambda', region_name=AWS_REGION)
    logger.info("Successfully initialized AWS clients")
except Exception as e:
    logger.error(f"Failed to initialize AWS clients: {str(e)}")
    raise

# Connect to MongoDB (DocumentDB)
try:
    client = MongoClient(
        MONGO_URI,
        tls=True,
        tlsCAFile='/var/www/medora-web-backend/global-bundle.pem'
    )
    db = client[MONGO_DB_NAME]
    patients_collection = db['patients']
    transcripts_collection = db['transcripts']
    visits_collection = db['visits']
    
    try:
        patients_collection.create_index("tenantId")
        transcripts_collection.create_index("tenantId")
        visits_collection.create_index("tenantId")
        logger.info("Created indexes on tenantId fields in MongoDB collections")
    except Exception as e:
        logger.error(f"Error creating indexes: {str(e)}")
    
    logger.info("Successfully connected to MongoDB")
except Exception as e:
    logger.error(f"Failed to connect to MongoDB: {str(e)}")
    raise

# Hardcoded subscription and user data
SUBSCRIPTIONS = {
    "doctor@allergyaffiliates.com": {"tier": "Premium", "trial_start": None, "card_last4": "1234"},
    "testuser@example.com": {"tier": "Trial", "trial_start": "2025-03-11", "card_last4": "5678"},
    "geepan1806@gmail.com": {"tier": "Premium", "trial_start": None, "card_last4": "7890"},
    "siddharthc@meditab.com": {"tier": "Premium", "trial_start": None, "card_last4": "9012"}
}

def get_subscription_status(email):
    """Return the subscription status including tier and trial expiration."""
    user_data = SUBSCRIPTIONS.get(email, {"tier": "None", "trial_start": None, "card_last4": None})
    tier = user_data["tier"]
    trial_start = user_data["trial_start"]
    if tier == "Trial" and trial_start:
        trial_start_date = datetime.strptime(trial_start, "%Y-%m-%d")
        trial_end = trial_start_date + timedelta(days=7)
        if datetime.now() > trial_end:
            return {"tier": "Expired", "trial_end": trial_end.strftime("%Y-%m-%d"), "card_last4": user_data["card_last4"]}
    return {"tier": tier, "trial_end": None, "card_last4": user_data["card_last4"]}

def validate_tenant_id(tenant_id, email=None):
    """
    Ensure tenant_id is valid and standardized
    If tenant_id is 'default_tenant' but email is provided, use email instead
    """
    if not tenant_id or tenant_id == 'default_tenant':
        if email:
            logger.info(f"Converting default_tenant to email: {email}")
            return email
        return 'default_tenant'
    return tenant_id

def get_soap_notes(patient_id, visit_id, tenant_id=None):
    """
    Get SOAP notes from DynamoDB with tenant filtering
    """
    try:
        response = dynamodb.get_item(
            TableName='MedoraSOAPNotes',
            Key={
                'patient_id': {'S': patient_id},
                'visit_id': {'S': visit_id}
            }
        )

        item = response.get('Item')
        if not item:
            logger.warning(f"No SOAP notes found for patient {patient_id}, visit {visit_id}")
            return None

        if tenant_id:
            item_tenant_id = item.get('tenantID', {}).get('S')
            if not item_tenant_id or item_tenant_id == tenant_id:
                soap_notes_json = item.get('soap_notes', {}).get('S')
                if soap_notes_json:
                    return json.loads(soap_notes_json)
                else:
                    logger.warning(f"SOAP notes field missing for patient {patient_id}, visit {visit_id}")
                    return None
            else:
                logger.warning(f"Tenant mismatch for patient {patient_id}, visit {visit_id}. Expected: {tenant_id}, Found: {item_tenant_id}")
                return None
        else:
            soap_notes_json = item.get('soap_notes', {}).get('S')
            if soap_notes_json:
                return json.loads(soap_notes_json)
            else:
                logger.warning(f"SOAP notes field missing for patient {patient_id}, visit {visit_id}")
                return None

    except Exception as e:
        logger.error(f"Error fetching SOAP notes from DynamoDB: {str(e)}")
        return None

def get_all_soap_notes_for_tenant(tenant_id):
    """
    Get all SOAP notes for a specific tenant
    """
    try:
        try:
            response = dynamodb.query(
                TableName='MedoraSOAPNotes',
                IndexName='tenantID-patient_id-index',
                KeyConditionExpression='tenantID = :tid',
                ExpressionAttributeValues={
                    ':tid': {'S': tenant_id}
                }
            )
            items = response.get('Items', [])
            logger.info(f"Found {len(items)} SOAP notes for tenant {tenant_id} using GSI")
            return items
        except Exception as e:
            logger.warning(f"GSI query failed, falling back to scan: {str(e)}")

            response = dynamodb.scan(
                TableName='MedoraSOAPNotes',
                FilterExpression='tenantID = :tid',
                ExpressionAttributeValues={
                    ':tid': {'S': tenant_id}
                }
            )
            items = response.get('Items', [])
            logger.info(f"Found {len(items)} SOAP notes for tenant {tenant_id} using scan")
            return items
    except Exception as e:
        logger.error(f"Error fetching SOAP notes for tenant {tenant_id}: {str(e)}")
        return []

def get_patient_insights(patient_id, tenant_id=None):
    """
    Get patient insights from DynamoDB with tenant filtering
    """
    try:
        if tenant_id:
            try:
                response = dynamodb.query(
                    TableName='MedoraPatientInsights',
                    IndexName='tenantID-patient_id-index',
                    KeyConditionExpression='tenantID = :tid AND patient_id = :pid',
                    ExpressionAttributeValues={
                        ':tid': {'S': tenant_id},
                        ':pid': {'S': patient_id}
                    }
                )
                items = response.get('Items', [])
                logger.info(f"Found {len(items)} insights for patient {patient_id} using GSI")
                return items
            except Exception as e:
                logger.warning(f"GSI query failed, falling back to scan: {str(e)}")

                response = dynamodb.scan(
                    TableName='MedoraPatientInsights',
                    FilterExpression='patient_id = :pid AND tenantID = :tid',
                    ExpressionAttributeValues={
                        ':pid': {'S': patient_id},
                        ':tid': {'S': tenant_id}
                    }
                )
                items = response.get('Items', [])
                logger.info(f"Found {len(items)} insights for patient {patient_id} using scan")
                return items
        else:
            response = dynamodb.query(
                TableName='MedoraPatientInsights',
                KeyConditionExpression='patient_id = :pid',
                ExpressionAttributeValues={
                    ':pid': {'S': patient_id}
                }
            )
            items = response.get('Items', [])
            logger.info(f"Found {len(items)} insights for patient {patient_id} without tenant filtering")
            return items
    except Exception as e:
        logger.error(f"Error fetching patient insights: {str(e)}")
        return []

def get_references(tenant_id=None):
    """
    Get references from DynamoDB with tenant filtering
    """
    try:
        if tenant_id:
            try:
                response = dynamodb.query(
                    TableName='MedoraReferences',
                    IndexName='tenantID-index',
                    KeyConditionExpression='tenantID = :tid',
                    ExpressionAttributeValues={
                        ':tid': {'S': tenant_id}
                    }
                )
                items = response.get('Items', [])
                logger.info(f"Found {len(items)} references for tenant {tenant_id} using GSI")
                return items
            except Exception as e:
                logger.warning(f"GSI query failed, falling back to scan: {str(e)}")

                response = dynamodb.scan(
                    TableName='MedoraReferences',
                    FilterExpression='tenantID = :tid',
                    ExpressionAttributeValues={
                        ':tid': {'S': tenant_id}
                    }
                )
                items = response.get('Items', [])
                logger.info(f"Found {len(items)} references for tenant {tenant_id} using scan")
                return items
        else:
            response = dynamodb.scan(TableName='MedoraReferences')
            items = response.get('Items', [])
            logger.info(f"Found {len(items)} references without tenant filtering")
            return items
    except Exception as e:
        logger.error(f"Error fetching references: {str(e)}")
        return []

def analyze_transcript(text, target_language="EN"):
    """
    FIXED: Analyze transcript and generate SOAP notes using xAI API - Always returns structured recommendations
    """
    headers = {
        "Authorization": f"Bearer {XAI_API_KEY}",
        "Content-Type": "application/json"
    }

    prompt = f"""
    You are an expert medical scribe AI assisting healthcare professionals. Analyze the following patient transcript and provide a detailed, professional-grade medical summary in JSON format with the following sections:

    - patient_history:
      - chief_complaint: [Specify the main issue, including duration and severity]
      - history_of_present_illness: [Provide a detailed narrative including onset, duration, frequency, severity of symptoms, specific triggers, associated symptoms, impact on daily life, exacerbating/alleviating factors, and prior treatments attempted]
      - past_medical_history: [Include all relevant past diagnoses, hospitalizations, surgeries, chronic conditions, and prior allergy/asthma management]
      - allergies: [List all allergies with known reactions and current management]
      - social_history: [Include relevant lifestyle factors, occupation, smoking/alcohol history, and environmental exposures]
      - review_of_systems: [Note additional symptoms across systems, e.g., fatigue, fever, weight changes]
    - physical_examination: [Infer physical findings based on the transcript or note if a physical exam is needed]
    - differential_diagnosis: [List primary diagnosis and 2-3 alternative diagnoses, considering severity and supporting evidence]
    - diagnostic_workup: [Recommend specific tests with rationale]
    - plan_of_care: [Provide a detailed treatment plan with specific medications, dosages, environmental controls, emergency management, long-term strategies, and follow-up schedule]
    - patient_education: [Provide specific advice for the patient on managing their condition, avoiding triggers, and adhering to the treatment plan]
    - follow_up_instructions: [Provide specific instructions for follow-up appointments, tests, or actions]
    - summary: [Summarize the visit in 2-3 sentences, including key findings, immediate actions, and next steps]
    - enhanced_recommendations: [CRITICAL: This MUST be a JSON object with these exact categories as keys, each containing an array of specific recommendations:
      {{
        "MEDICATION MANAGEMENT": ["Detailed medication recommendation 1", "Detailed medication recommendation 2"],
        "LIFESTYLE MODIFICATIONS": ["Specific lifestyle change 1", "Specific lifestyle change 2"],
        "MONITORING PROTOCOL": ["Monitoring instruction 1", "Monitoring instruction 2"],
        "EMERGENCY ACTION PLAN": ["Emergency instruction 1", "Emergency instruction 2"],
        "LONG-TERM MANAGEMENT STRATEGY": ["Long-term strategy 1", "Long-term strategy 2"],
        "PATIENT EDUCATION RESOURCES": ["Education resource 1", "Education resource 2"],
        "FOLLOW-UP SCHEDULE": ["Follow-up instruction 1", "Follow-up instruction 2"]
      }}
    ]

    Transcript: {text}

    CRITICAL: For enhanced_recommendations, you MUST return a JSON object with the exact category names above, each containing an array of specific recommendations. Do NOT return a string.

    Output in JSON format:
    {{
        "patient_history": {{
            "chief_complaint": "string",
            "history_of_present_illness": "string",
            "past_medical_history": "string",
            "allergies": "string",
            "social_history": "string",
            "review_of_systems": "string"
        }},
        "physical_examination": "string",
        "differential_diagnosis": "string",
        "diagnostic_workup": "string",
        "plan_of_care": "string",
        "patient_education": "string",
        "follow_up_instructions": "string",
        "summary": "string",
        "enhanced_recommendations": {{
            "MEDICATION MANAGEMENT": ["recommendation1", "recommendation2"],
            "LIFESTYLE MODIFICATIONS": ["recommendation1", "recommendation2"],
            "MONITORING PROTOCOL": ["recommendation1", "recommendation2"],
            "EMERGENCY ACTION PLAN": ["recommendation1", "recommendation2"],
            "LONG-TERM MANAGEMENT STRATEGY": ["recommendation1", "recommendation2"],
            "PATIENT EDUCATION RESOURCES": ["recommendation1", "recommendation2"],
            "FOLLOW-UP SCHEDULE": ["recommendation1", "recommendation2"]
        }}
    }}
    """

    payload = {
        "model": "grok-2-1212",
        "messages": [
            {"role": "system", "content": "You are an expert medical scribe AI. Generate comprehensive SOAP notes in JSON format. For enhanced_recommendations, always return a JSON object with category arrays, never a string."},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 2500,
        "temperature": 0.25
    }

    try:
        logger.debug(f"Sending request to xAI API: URL={XAI_API_URL}, Headers={headers}, Payload={payload}")
        response = requests.post(XAI_API_URL, headers=headers, json=payload, timeout=45)
        logger.debug(f"xAI API response: Status={response.status_code}, Body={response.text}")
        response.raise_for_status()
        result = response.json()

        if "choices" in result and len(result["choices"]) > 0:
            response_text = result["choices"][0]["message"]["content"]
            logger.info(f"Raw xAI response: {response_text}")

            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            if start_idx != -1 and end_idx != -1:
                json_str = response_text[start_idx:end_idx].strip()
                try:
                    parsed_data = json.loads(json_str)
                    logger.info(f"Parsed JSON: {parsed_data}")

                    # CRITICAL FIX: Handle enhanced_recommendations properly
                    if "enhanced_recommendations" in parsed_data:
                        enhanced_recs = parsed_data["enhanced_recommendations"]
                        
                        # If it's a string, convert it to structured format
                        if isinstance(enhanced_recs, str):
                            logger.warning("üö® Enhanced recommendations returned as string, converting to structured format")
                            parsed_data["enhanced_recommendations"] = force_create_structured_recommendations(text)
                        
                        # If it's a list, convert it to structured format
                        elif isinstance(enhanced_recs, list):
                            logger.warning("üö® Enhanced recommendations returned as list, converting to structured format")
                            parsed_data["enhanced_recommendations"] = convert_list_to_structured_recommendations(enhanced_recs)
                        
                        # If it's already a dict, ensure it has the right structure
                        elif isinstance(enhanced_recs, dict):
                            # Validate that it has the expected categories
                            expected_categories = [
                                "MEDICATION MANAGEMENT",
                                "LIFESTYLE MODIFICATIONS",
                                "MONITORING PROTOCOL",
                                "EMERGENCY ACTION PLAN",
                                "LONG-TERM MANAGEMENT STRATEGY",
                                "PATIENT EDUCATION RESOURCES",
                                "FOLLOW-UP SCHEDULE"
                            ]
                            
                            # If it doesn't have the expected structure, force create
                            if not any(cat in enhanced_recs for cat in expected_categories):
                                logger.warning("üö® Enhanced recommendations dict doesn't have expected categories, recreating")
                                parsed_data["enhanced_recommendations"] = force_create_structured_recommendations(text)
                            else:
                                logger.info("‚úÖ Enhanced recommendations properly structured")
                        
                        else:
                            # Fallback for any other type
                            logger.warning(f"üö® Enhanced recommendations unexpected type: {type(enhanced_recs)}, creating fallback")
                            parsed_data["enhanced_recommendations"] = force_create_structured_recommendations(text)
                    
                    else:
                        # No enhanced_recommendations field, create it
                        logger.warning("üö® No enhanced_recommendations field found, creating structured recommendations")
                        parsed_data["enhanced_recommendations"] = force_create_structured_recommendations(text)

                    # Translate if needed
                    if target_language.upper() != "EN":
                        for key, value in parsed_data.items():
                            if isinstance(value, dict):
                                for k, v in value.items():
                                    if isinstance(v, str):
                                        translated = translate_text(v, target_language)
                                        parsed_data[key][k] = translated
                            elif isinstance(value, str):
                                translated = translate_text(value, target_language)
                                parsed_data[key] = translated
                    
                    logger.info(f"‚úÖ Final enhanced_recommendations type: {type(parsed_data.get('enhanced_recommendations'))}")
                    return parsed_data
                    
                except json.JSONDecodeError as e:
                    logger.error(f"JSON parsing error: {e} with raw data: {json_str[:e.pos + 20]}...")
                    return create_forced_structured_response(text, f"JSON parsing error: {str(e)}")
            else:
                logger.error(f"No valid JSON object found in response: {response_text}")
                return create_forced_structured_response(text, "No valid JSON found in AI response")
        
        return create_forced_structured_response(text, "No choices in AI response")
        
    except requests.exceptions.HTTPError as http_err:
        error_message = f"HTTP Error: {http_err.response.status_code} - {http_err.response.text}"
        logger.error(f"Error calling xAI API: {error_message}")
        return create_forced_structured_response(text, error_message)
    except Exception as e:
        logger.error(f"Error calling xAI API: {str(e)}")
        return create_forced_structured_response(text, str(e))

def create_forced_structured_response(transcript, error_msg):
    """
    Create complete structured response when everything fails
    """
    return {
        "patient_history": {
            "chief_complaint": "Medical consultation for ongoing health management",
            "history_of_present_illness": "Patient presents with ongoing management needs for chronic conditions",
            "past_medical_history": "History of chronic conditions requiring ongoing treatment",
            "allergies": "Multiple environmental and potential drug allergies under evaluation",
            "social_history": "Environmental and occupational factors contributing to symptom management",
            "review_of_systems": "Multiple systems affected requiring comprehensive evaluation"
        },
        "physical_examination": "Clinical assessment completed with focus on presenting symptoms",
        "differential_diagnosis": "Primary diagnosis requiring ongoing management with consideration of multiple contributing factors",
        "diagnostic_workup": "Comprehensive testing and evaluation as clinically indicated",
        "plan_of_care": "Comprehensive management approach including medication optimization and lifestyle modifications",
        "patient_education": "Patient education provided on condition management and treatment adherence",
        "follow_up_instructions": "Regular follow-up scheduled for ongoing monitoring and treatment adjustment",
        "summary": f"Comprehensive evaluation completed with structured treatment plan (Processing note: {error_msg})",
        "enhanced_recommendations": force_create_structured_recommendations(transcript)
    }

def analyze_transcript_freed_style(text, target_language="EN"):
    """
    Generate Freed-style condition-focused plans instead of templated categories
    """
    # First, extract conditions from the transcript
    conditions_prompt = f"""
    You are a medical AI analyzing a doctor-patient conversation. Your task is to identify the PRIMARY MEDICAL CONDITIONS discussed in this transcript.

    TRANSCRIPT: {text}

    INSTRUCTIONS:
    1. Identify the main medical conditions/diagnoses mentioned or implied
    2. Focus on conditions the doctor is actually addressing or planning for
    3. Return as a simple JSON list of conditions

    OUTPUT FORMAT:
    {{
        "conditions": [
            "condition1",
            "condition2",
            "condition3"
        ]
    }}

    Only include conditions that were actually discussed or that the doctor is treating.
    """

    # Get conditions first
    headers = {
        "Authorization": f"Bearer {XAI_API_KEY}",
        "Content-Type": "application/json"
    }

    conditions_payload = {
        "model": "grok-2-1212",
        "messages": [
            {"role": "system", "content": "You are a medical AI that identifies conditions from transcripts. Return only valid JSON."},
            {"role": "user", "content": conditions_prompt}
        ],
        "max_tokens": 500,
        "temperature": 0.1
    }

    try:
        response = requests.post(XAI_API_URL, headers=headers, json=conditions_payload, timeout=30)
        response.raise_for_status()
        result = response.json()
        
        conditions = []
        if "choices" in result and len(result["choices"]) > 0:
            response_text = result["choices"][0]["message"]["content"]
            try:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
                if start_idx != -1 and end_idx != -1:
                    json_str = response_text[start_idx:end_idx].strip()
                    conditions_data = json.loads(json_str)
                    conditions = conditions_data.get("conditions", [])
            except:
                pass
        
        # Fallback conditions if extraction fails
        if not conditions:
            conditions = ["Allergic Rhinitis", "Medication Management", "Follow-up Care"]
            
        logger.info(f"Extracted conditions: {conditions}")
        
    except Exception as e:
        logger.error(f"Error extracting conditions: {str(e)}")
        conditions = ["Allergic Rhinitis", "Medication Management", "Follow-up Care"]

    # Now generate the Freed-style plan
    freed_prompt = f"""
    You are an expert allergist creating a comprehensive treatment plan in the style of Dr. Freed. Analyze this doctor-patient conversation and create a condition-focused plan.

    TRANSCRIPT: {text}

    IDENTIFIED CONDITIONS: {', '.join(conditions)}

    INSTRUCTIONS:
    Create a detailed plan organized by medical conditions using EXACTLY this format:

    For each condition, write:
    "In regards to [Condition Name]:
    * [Detailed narrative point about this condition]
    * [Another detailed point with specific actions]
    * [Treatment plan specific to this condition]"

    FREED-STYLE REQUIREMENTS:
    1. Use "In regards to [condition]:" as section headers
    2. Each bullet point should be a complete, detailed sentence
    3. Include specific medications, dosages, and instructions mentioned
    4. Be thorough and narrative - not just bullet points
    5. Include patient education and follow-up plans for each condition
    6. Make it sound like how an experienced allergist would document plans

    EXAMPLE FORMAT:
    In regards to Allergic Rhinitis:
    * Patient has history of allergic rhinitis diagnosed in Cuba with persistent symptoms including sneezing, itchy and watery eyes, and nasal congestion that are present year-round and have worsened since relocating.
    * Previous treatments included loratadine, desloratadine, and cetirizine as recommended by ENT specialist, with patient receiving allergy shots for approximately 3 months in Cuba.
    * Plan to perform comprehensive allergy testing today to identify specific allergens and develop targeted treatment approach.
    * Patient has discontinued all allergy medications for the past month in preparation for testing, which will help ensure accurate results.

    In regards to Possible Asthma:
    * Patient reports increased coughing and respiratory symptoms suggestive of possible asthma component to allergic disease.
    * Plan to conduct pulmonary function testing to assess respiratory status and determine if asthma is present.
    * Will evaluate response to bronchodilator therapy and consider appropriate controller medications if asthma is confirmed.

    Now create the complete plan with all relevant conditions from the transcript:
    """

    main_payload = {
        "model": "grok-2-1212",
        "messages": [
            {"role": "system", "content": "You are Dr. Freed, an experienced allergist. Create detailed, condition-focused treatment plans. Use 'In regards to [condition]:' format with detailed narrative bullet points."},
            {"role": "user", "content": freed_prompt}
        ],
        "max_tokens": 2500,
        "temperature": 0.2
    }

    try:
        response = requests.post(XAI_API_URL, headers=headers, json=main_payload, timeout=45)
        response.raise_for_status()
        result = response.json()

        freed_plan = ""
        if "choices" in result and len(result["choices"]) > 0:
            freed_plan = result["choices"][0]["message"]["content"]
            logger.info(f"Generated Freed-style plan: {freed_plan}")

        # Generate other SOAP sections normally
        standard_soap_prompt = f"""
        Analyze the following medical transcript and provide detailed SOAP notes in JSON format:

        TRANSCRIPT: {text}

        Provide comprehensive analysis for:
        - patient_history (chief_complaint, history_of_present_illness, past_medical_history, allergies, social_history, review_of_systems)
        - physical_examination
        - differential_diagnosis
        - diagnostic_workup
        - patient_education
        - follow_up_instructions
        - summary

        Output in JSON format with these exact field names.
        """

        soap_payload = {
            "model": "grok-2-1212",
            "messages": [
                {"role": "system", "content": "You are a medical scribe AI. Generate comprehensive SOAP notes in JSON format."},
                {"role": "user", "content": standard_soap_prompt}
            ],
            "max_tokens": 2500,
            "temperature": 0.2
        }

        soap_response = requests.post(XAI_API_URL, headers=headers, json=soap_payload, timeout=45)
        soap_response.raise_for_status()
        soap_result = soap_response.json()

        # Parse SOAP response
        soap_data = {}
        if "choices" in soap_result and len(soap_result["choices"]) > 0:
            soap_text = soap_result["choices"][0]["message"]["content"]
            try:
                start_idx = soap_text.find('{')
                end_idx = soap_text.rfind('}') + 1
                if start_idx != -1 and end_idx != -1:
                    json_str = soap_text[start_idx:end_idx].strip()
                    soap_data = json.loads(json_str)
            except json.JSONDecodeError as e:
                logger.error(f"Error parsing SOAP JSON: {str(e)}")

        # FIXED: Safely handle differential_diagnosis that might be a list or string
        def safe_get_diagnosis_text(soap_data):
            """Safely extract diagnosis text, handling both string and list formats"""
            diagnosis = soap_data.get("differential_diagnosis", "N/A")
            
            if isinstance(diagnosis, list):
                # If it's a list, join the items or take the first one
                if diagnosis:
                    return diagnosis[0] if len(diagnosis) == 1 else "; ".join(str(d) for d in diagnosis)
                else:
                    return "N/A"
            elif isinstance(diagnosis, str):
                return diagnosis
            else:
                # Handle any other data type
                return str(diagnosis) if diagnosis else "N/A"

        # Get diagnosis text safely
        diagnosis_text = safe_get_diagnosis_text(soap_data)
        condition_summary = diagnosis_text.split('\n')[0] if diagnosis_text != "N/A" else "N/A"

        # Combine everything with Freed-style plan
        final_result = {
            "patient_history": soap_data.get("patient_history", {
                "chief_complaint": "Patient presents with allergy symptoms",
                "history_of_present_illness": "Detailed history needed",
                "past_medical_history": "See transcript",
                "allergies": "Multiple allergies noted",
                "social_history": "Environmental factors considered",
                "review_of_systems": "Multiple systems affected"
            }),
            "physical_examination": soap_data.get("physical_examination", "Physical examination findings as discussed"),
            "differential_diagnosis": diagnosis_text,  # Use the safely extracted diagnosis
            "diagnostic_workup": soap_data.get("diagnostic_workup", "Comprehensive allergy testing planned"),
            "plan_of_care": freed_plan,  # This is the key change - Freed-style plan
            "patient_education": soap_data.get("patient_education", "Patient education provided"),
            "follow_up_instructions": soap_data.get("follow_up_instructions", "Follow-up as planned"),
            "summary": soap_data.get("summary", "Comprehensive allergy evaluation and treatment plan established"),
            "enhanced_recommendations": soap_data.get("enhanced_recommendations", "Evidence-based recommendations provided")
        }

        return final_result

    except Exception as e:
        logger.error(f"Error generating Freed-style plan: {str(e)}")
        # Fallback to basic structure
        return {
            "patient_history": {
                "chief_complaint": "Allergy consultation",
                "history_of_present_illness": "See transcript details",
                "past_medical_history": "Multiple allergic conditions",
                "allergies": "Various allergens identified",
                "social_history": "Environmental factors noted",
                "review_of_systems": "Allergic symptoms across systems"
            },
            "physical_examination": "Physical findings as noted",
            "differential_diagnosis": "Allergic rhinitis and related conditions",
            "diagnostic_workup": "Comprehensive allergy testing",
            "plan_of_care": f"In regards to Allergy Management:\n* Comprehensive evaluation planned\n* Testing to be performed\n* Treatment plan to be developed based on results",
            "patient_education": "Allergy management education provided",
            "follow_up_instructions": "Follow-up as scheduled",
            "summary": "Allergy consultation completed with plan established"
        }

# Load the private key for JWT signing
try:
    with open(PRIVATE_KEY_PATH, 'r') as f:
        PRIVATE_KEY = f.read()
    logger.info("Successfully loaded private key for IMS FHIR authentication")
except Exception as e:
    logger.error(f"Failed to load private key: {str(e)}")
    raise

def generate_jwt_assertion():
    try:
        now = int(time.time())
        payload = {
            "sub": IMS_CLIENT_ID,
            "aud": IMS_TOKEN_ENDPOINT,
            "iss": IMS_CLIENT_ID,
            "exp": now + 300,
            "iat": now,
            "jti": str(uuid.uuid4())
        }
        assertion = jwt.encode(payload, PRIVATE_KEY, algorithm="RS384")
        logger.debug(f"Generated JWT assertion: {assertion}")
        return assertion
    except Exception as e:
        logger.error(f"Failed to generate JWT assertion: {str(e)}")
        return None

def get_fhir_access_token():
    try:
        assertion = generate_jwt_assertion()
        if not assertion:
            raise ValueError("Failed to generate JWT assertion")
        headers = {
            "Content-Type": "application/x-www-form-urlencoded"
        }
        payload = {
            "client_assertion_type": "urn:ietf:params:oauth:client-assertion-type:jwt-bearer",
            "grant_type": "client_credentials",
            "client_id": IMS_CLIENT_ID,
            "client_assertion": assertion
        }
        logger.debug(f"Sending token request to IMS: {IMS_TOKEN_ENDPOINT}")
        response = requests.post(IMS_TOKEN_ENDPOINT, headers=headers, data=payload, timeout=10)
        response.raise_for_status()
        token_data = response.json()
        access_token = token_data.get("access_token")
        if not access_token:
            raise ValueError("No access token in response")
        logger.info("Successfully obtained IMS FHIR access token")
        return access_token
    except Exception as e:
        if hasattr(e, 'response') and e.response is not None:
            logger.error(f"Failed to get IMS FHIR access token: {str(e)} - Response: {e.response.text}")
        else:
            logger.error(f"Failed to get IMS FHIR access token: {str(e)}")
        return None

def push_to_fhir_server(patient_id, visit_id, tenant_id):
    try:
        access_token = get_fhir_access_token()
        if not access_token:
            raise ValueError("Failed to obtain FHIR access token")
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/fhir+json"
        }
        patient = patients_collection.find_one({"_id": ObjectId(patient_id), "tenantId": tenant_id})
        if not patient:
            raise ValueError(f"Patient {patient_id} not found")
        fhir_patient = {
            "resourceType": "Patient",
            "id": patient_id,
            "name": [{"text": patient.get("name", "Unknown Patient")}],
            "birthDate": None,
            "meta": {"tag": [{"system": "http://medora.ai/tenant", "code": tenant_id}]}
        }
        response = requests.put(
            f"{IMS_FHIR_SERVER_URL}/Patient/{patient_id}",
            headers=headers,
            json=fhir_patient,
            timeout=10
        )
        response.raise_for_status()
        logger.info(f"Pushed Patient {patient_id} to IMS FHIR server")
        visit = visits_collection.find_one({"visitId": visit_id, "tenantId": tenant_id})
        if not visit:
            raise ValueError(f"Visit {visit_id} not found")
        fhir_encounter = {
            "resourceType": "Encounter",
            "id": visit_id,
            "status": "finished" if visit.get("status") == "completed" else "in-progress",
            "subject": {"reference": f"Patient/{patient_id}"},
            "period": {"start": visit.get("startTime")},
            "meta": {"tag": [{"system": "http://medora.ai/tenant", "code": tenant_id}]}
        }
        response = requests.put(
            f"{IMS_FHIR_SERVER_URL}/Encounter/{visit_id}",
            headers=headers,
            json=fhir_encounter,
            timeout=10
        )
        response.raise_for_status()
        logger.info(f"Pushed Encounter {visit_id} to IMS FHIR server")
        soap_notes = get_soap_notes(patient_id, visit_id, tenant_id)
        if not soap_notes:
            logger.warning(f"No SOAP notes found for patient {patient_id}, visit {visit_id}")
            return True
        fhir_observation = {
            "resourceType": "Observation",
            "id": f"{visit_id}-soap",
            "status": "final",
            "code": {"text": "SOAP Notes"},
            "subject": {"reference": f"Patient/{patient_id}"},
            "encounter": {"reference": f"Encounter/{visit_id}"},
            "valueString": json.dumps(soap_notes),
            "meta": {"tag": [{"system": "http://medora.ai/tenant", "code": tenant_id}]}
        }
        response = requests.put(
            f"{IMS_FHIR_SERVER_URL}/Observation/{visit_id}-soap",
            headers=headers,
            json=fhir_observation,
            timeout=10
        )
        response.raise_for_status()
        logger.info(f"Pushed SOAP notes as Observation for visit {visit_id} to IMS FHIR server")
        return True
    except Exception as e:
        logger.error(f"Failed to push data to IMS FHIR server: {str(e)}")
        return False

# ================================
# ENHANCED ALLERGENIQ API ENDPOINT
# ================================

@app.route('/api/allergeniq-profile', methods=['GET', 'OPTIONS'])
def get_allergeniq_profile():
    """FRONTEND COMPATIBLE: Enhanced AllergenIQ with frontend compatibility layer"""
    logger.info("üîß ALLERGENIQ API: Using enhanced extraction with frontend compatibility")
    
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "*")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "GET, OPTIONS")
        return response
    
    try:
        # Get parameters
        patient_id = request.args.get('patient_id')
        visit_id = request.args.get('visit_id')
        email = request.args.get('email')
        tenant_id = request.args.get('tenantId', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)
        
        if not patient_id or not visit_id:
            return jsonify({
                "success": False,
                "error": "patient_id and visit_id are required"
            }), 400
        
        logger.info(f"üîß ALLERGENIQ: Processing patient {patient_id}, visit {visit_id} with compatibility layer")
        
        # Get SOAP notes
        soap_notes = get_soap_notes(patient_id, visit_id, tenant_id)
        if not soap_notes:
            logger.warning(f"‚ö†Ô∏è No SOAP notes found for patient {patient_id}, visit {visit_id}")
            return jsonify({
                "success": False,
                "error": "No SOAP notes found for this patient/visit"
            }), 404
        
        # ENHANCED: Use new NLP-based extraction
        try:
            logger.info("üî¨ Using enhanced NLP extraction")
            enhanced_profile_data = structure_allergeniq_data_enhanced(soap_notes, [], None)
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Enhanced extraction failed, using fallback: {str(e)}")
            enhanced_profile_data = create_safe_frontend_fallback()
        
        # COMPATIBILITY: Convert enhanced data to frontend-expected format
        profile_data = ensure_frontend_compatibility(enhanced_profile_data)
        
        # Get patient details
        patient_name = "Unknown Patient"
        patient_age = None
        try:
            patient_doc = patients_collection.find_one({"_id": ObjectId(patient_id), "tenantId": tenant_id})
            if not patient_doc:
                patient_doc = patients_collection.find_one({"name": patient_id, "tenantId": tenant_id})
            if patient_doc:
                patient_name = patient_doc.get("name", "Unknown Patient")
                patient_age = patient_doc.get("age")
        except Exception as e:
            logger.warning(f"Could not retrieve patient details: {str(e)}")
        
        # Get visit date
        visit_date = datetime.now().isoformat().split('T')[0]
        try:
            visit_doc = visits_collection.find_one({"visitId": visit_id, "tenantId": tenant_id})
            if visit_doc and "startTime" in visit_doc:
                visit_date = visit_doc["startTime"].split('T')[0]
        except Exception as e:
            logger.warning(f"Could not retrieve visit date: {str(e)}")
        
        # COMPATIBLE RESPONSE: Same structure as before, but with enhanced data
        result = {
            "success": True,
            "patient_id": patient_id,
            "visit_id": visit_id,
            "patient_name": patient_name,
            "patient_age": patient_age,
            "visit_date": visit_date,
            "profile": profile_data,  # Frontend-compatible enhanced data
            "extraction_method": "Enhanced NLP with frontend compatibility",
            "enhanced": True,  # Flag indicating enhanced extraction was used
            "compatible": True  # Flag indicating frontend compatibility ensured
        }
        
        logger.info("‚úÖ ALLERGENIQ: Successfully generated compatible enhanced profile")
        return jsonify(result), 200
        
    except Exception as e:
        logger.error(f"‚ùå ALLERGENIQ: Error generating profile: {str(e)}")
        
        # SAFE ERROR RESPONSE: Return compatible fallback even on error
        return jsonify({
            "success": True,  # Don't break frontend with false
            "patient_id": patient_id if 'patient_id' in locals() else "unknown",
            "visit_id": visit_id if 'visit_id' in locals() else "unknown",
            "patient_name": "Unknown Patient",
            "patient_age": None,
            "visit_date": datetime.now().isoformat().split('T')[0],
            "profile": create_safe_frontend_fallback(),
            "extraction_method": "Safe fallback due to error",
            "error_details": str(e),
            "enhanced": False,
            "compatible": True
        }), 200  # Return 200 to prevent frontend errors

# ================================
# REST OF ORIGINAL FLASK ROUTES
# ================================

@app.route('/api/transcribe-audio', methods=['POST'])
def transcribe_audio():
    if 'audio' not in request.files:
        return jsonify({"success": False, "error": "No audio file provided"}), 400

    audio_file = request.files['audio']
    email = request.form.get('email')
    tenant_id = request.form.get('tenantId', 'default_tenant')
    tenant_id = validate_tenant_id(tenant_id, email)

    try:
        audio_key = f"audio/{tenant_id}/{datetime.now().isoformat()}_{audio_file.filename}"
        s3_client.upload_fileobj(audio_file, S3_BUCKET, audio_key)
        audio_uri = f"s3://{S3_BUCKET}/{audio_key}"
        logger.info(f"Uploaded audio file to S3: {audio_uri}")
    except Exception as e:
        logger.error(f"Error uploading audio to S3: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500

    try:
        job_name = f"HealthScribeJob_{datetime.now().isoformat().replace(':', '-')}"
        transcribe_client.start_medical_transcription_job(
            MedicalTranscriptionJobName=job_name,
            LanguageCode='en-US',
            MediaFormat=audio_file.filename.split('.')[-1],
            Media={'MediaFileUri': audio_uri},
            OutputBucketName=S3_BUCKET,
            Specialty='PRIMARYCARE',
            Type='CONVERSATION',
            Settings={
                'ShowSpeakerLabels': True,
                'MaxSpeakerLabels': 2,
                'ChannelIdentification': False
            }
        )
        logger.info(f"Started HealthScribe transcription job: {job_name}")

        while True:
            status = transcribe_client.get_medical_transcription_job(MedicalTranscriptionJobName=job_name)
            if status['MedicalTranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:
                break
            logger.debug(f"Waiting for transcription job {job_name} to complete...")
            time.sleep(5)

        if status['MedicalTranscriptionJob']['TranscriptionJobStatus'] == 'COMPLETED':
            transcript_file_uri = status['MedicalTranscriptionJob']['Transcript']['TranscriptFileUri']
            transcript_key = transcript_file_uri.split('/')[-1]
            transcript_obj = s3_client.get_object(Bucket=S3_BUCKET, Key=transcript_key)
            transcript_data = json.loads(transcript_obj['Body'].read().decode())
            transcript_text = transcript_data['results']['transcripts'][0]['transcript']
            logger.info(f"Transcription completed for job {job_name}")
            return jsonify({"success": True, "transcript": transcript_text}), 200
        else:
            logger.error(f"Transcription job {job_name} failed: {status['MedicalTranscriptionJob'].get('FailureReason', 'Unknown reason')}")
            return jsonify({"success": False, "error": "Transcription job failed"}), 500
    except Exception as e:
        logger.error(f"Error with HealthScribe transcription: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/create-patient', methods=['POST', 'OPTIONS'])
def create_patient():
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "https://test.medoramd.ai")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response
    try:
        data = request.get_json()
        email = data.get('email')
        tenant_id = data.get('tenantId', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)
        name = data.get('name')
        age = data.get('age')
        medical_history = data.get('medicalHistory', '')

        if not name or age is None:
            return jsonify({"success": False, "error": "Missing required fields: name or age"}), 400

        patient_doc = {
            "tenantId": tenant_id,
            "name": name,
            "age": int(age),
            "medicalHistory": medical_history,
            "createdAt": datetime.now().isoformat()
        }
        result = patients_collection.insert_one(patient_doc)
        patient_id = str(result.inserted_id)
        logger.info(f"Created patient with ID {patient_id} in tenant {tenant_id}")

        return jsonify({"success": True, "patientId": patient_id}), 200
    except Exception as e:
        logger.error(f'Error processing /api/create-patient request: {str(e)}')
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/debug/patients', methods=['GET'])
def debug_patients():
    try:
        all_patients = list(patients_collection.find({}, {"name": 1, "tenantId": 1}))
        result = []
        for patient in all_patients:
            result.append({
                "id": str(patient["_id"]),
                "name": patient.get("name", "Unknown"),
                "tenantId": patient.get("tenantId", "MISSING")
            })
        
        tenant_counts = {}
        for patient in result:
            tenant_id = patient.get("tenantId", "MISSING")
            tenant_counts[tenant_id] = tenant_counts.get(tenant_id, 0) + 1
        
        return jsonify({
            "patients": result,
            "tenant_counts": tenant_counts,
            "total_patients": len(result)
        }), 200
    except Exception as e:
        logger.error(f"Error in debug endpoint: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/get-patients', methods=['GET'])
def get_patients():
    try:
        email = request.args.get('email')
        tenant_id = request.args.get('tenantId', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)
        
        logger.info(f"Fetching patients for tenant_id: {tenant_id}")
        
        patients = list(patients_collection.find({"tenantId": tenant_id}))
        
        logger.info(f"Found {len(patients)} patients for tenant {tenant_id}")
        
        for patient in patients:
            patient["patientId"] = str(patient["_id"])
            patient.pop("_id")
        
        return jsonify({"success": True, "patients": patients}), 200
    except Exception as e:
        logger.error(f'Error processing /api/get-patients request: {str(e)}')
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/fetchPatients', methods=['GET'])
def fetch_patients():
    try:
        return get_patients()
    except Exception as e:
        logger.error(f'Error processing /api/fetchPatients request: {str(e)}')
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/get-patient-history', methods=['GET'])
def get_patient_history():
    try:
        email = request.args.get('email')
        tenant_id = request.args.get('tenantId', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)
        patient_id = request.args.get('patientId')

        if not patient_id:
            return jsonify({"success": False, "error": "Missing patientId"}), 400

        logger.info(f"Fetching history for patient {patient_id} in tenant {tenant_id}")
        transcripts = list(transcripts_collection.find({"tenantId": tenant_id, "patientId": patient_id}))
        for transcript in transcripts:
            transcript["id"] = str(transcript["_id"])
            transcript.pop("_id")
        logger.info(f"Retrieved {len(transcripts)} transcripts for patient {patient_id} in tenant {tenant_id}")
        return jsonify({"success": True, "transcripts": transcripts}), 200
    except Exception as e:
        logger.error(f'Error processing /api/get-patient-history request: {str(e)}')
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/visit/start', methods=['POST', 'OPTIONS'])
def start_visit():
    if request.method == 'OPTIONS':
        logger.info("Handling OPTIONS request for /api/visit/start")
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "https://test.medoramd.ai")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response
    logger.info("Handling POST request for /api/visit/start")
    try:
        logger.debug(f"Request headers: {request.headers}")
        logger.debug(f"Request JSON: {request.get_json()}")

        data = request.get_json()
        patient_id = data.get('patientId')
        email = data.get('email')
        tenant_id = data.get('tenantId', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)

        logger.debug(f"Received data - patientId: {patient_id}, email: {email}, tenantId: {tenant_id}")

        if not patient_id or not email:
            logger.error("Missing required fields: patientId or email")
            return jsonify({"success": False, "error": "Patient ID and email are required"}), 400

        logger.debug("Checking subscription status")
        status = get_subscription_status(email)
        logger.debug(f"Subscription status: {status}")
        if status["tier"] not in ["Trial", "Premium"]:
            logger.error(f"Active subscription required for email: {email}")
            return jsonify({"success": False, "error": "Active subscription required"}), 403
        if status["tier"] == "Expired":
            logger.error(f"Trial expired for email: {email} on {status['trial_end']}")
            return jsonify({"success": False, "error": f"Trial expired on {status['trial_end']}"}), 403

        logger.debug("Finding patient in MongoDB")
        patient = patients_collection.find_one({"tenantId": tenant_id, "name": patient_id})
        logger.debug(f"Patient found: {patient}")
        if not patient:
            logger.info(f"Patient {patient_id} not found, creating new patient")
            patient_doc = {
                "tenantId": tenant_id,
                "name": patient_id,
                "age": None,
                "medicalHistory": None,
                "createdAt": datetime.now().isoformat()
            }
            patient_result = patients_collection.insert_one(patient_doc)
            patient_id = str(patient_result.inserted_id)
            logger.info(f"Created new patient with ID: {patient_id}")
        else:
            patient_id = str(patient["_id"])
            logger.info(f"Using existing patient ID: {patient_id}")

        logger.debug("Creating visit document")
        visit_id = str(uuid.uuid4())
        visit_doc = {
            "visitId": visit_id,
            "tenantId": tenant_id,
            "patientId": patient_id,
            "clinicianEmail": email,
            "startTime": datetime.now().isoformat(),
            "status": "active"
        }
        logger.debug(f"Inserting visit document: {visit_doc}")
        visits_collection.insert_one(visit_doc)
        logger.info(f"Visit started: {visit_id} for patient {patient_id} by {email}")

        return jsonify({"success": True, "message": "Visit started", "visitId": visit_id, "patientId": patient_id}), 201
    except Exception as e:
        logger.error(f"Error starting visit: {str(e)}")
        logger.error(f"Exception traceback: {str(e.__traceback__)}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/delete-patient', methods=['POST', 'OPTIONS'])
def delete_patient():
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "https://test.medoramd.ai")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response
    try:
        data = request.get_json()
        patient_id = data.get('patientId')
        email = data.get('email')
        tenant_id = data.get('tenantId', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)

        if not patient_id:
            return jsonify({"success": False, "error": "Missing patientId"}), 400

        result = patients_collection.delete_one({"_id": ObjectId(patient_id), "tenantId": tenant_id})
        if result.deleted_count == 0:
            return jsonify({"success": False, "error": "Patient not found"}), 404

        transcripts_collection.delete_many({"patientId": patient_id, "tenantId": tenant_id})
        visits_collection.delete_many({"patientId": patient_id, "tenantId": tenant_id})

        logger.info(f"Deleted patient {patient_id} and associated data in tenant {tenant_id}")
        return jsonify({"success": True, "message": "Patient deleted successfully"}), 200
    except Exception as e:
        logger.error(f'Error processing /api/delete-patient request: {str(e)}')
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/analyze', methods=['POST', 'OPTIONS'])
def analyze_endpoint():
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "http://127.0.0.1:8080")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type, Authorization")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response
    try:
        data = request.get_json()
        email = data.get('email')
        visit_id = data.get('visitId')
        status = get_subscription_status(email)
        tenant_id = data.get('tenantId', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)

        tier = status["tier"]
        trial_end = status["trial_end"]

        if tier == "None":
            return jsonify({"success": False, "error": "Please register to start your free trial"}), 403
        elif tier == "Expired":
            return jsonify({"success": False, "error": f"Free trial expired on {trial_end}. Upgrade to Premium or add payment."}), 403
        elif tier == "Basic":
            return jsonify({"success": False, "error": "Upgrade to Premium for transcript analysis"}), 403

        text = data.get('text', '')
        target_language = data.get('language', 'EN')

        if not text:
            return jsonify({"success": False, "error": "Text is required"}), 400
        if not visit_id:
            return jsonify({"success": False, "error": "Visit ID is required"}), 400

        visit = visits_collection.find_one({"visitId": visit_id, "tenantId": tenant_id})
        if not visit:
            return jsonify({"success": False, "error": "Invalid or missing visit ID"}), 400

        patient_id = visit["patientId"]

        result = analyze_transcript(text, target_language)

        recommendations = result.get("enhanced_recommendations", result.get("patient_education", "N/A"))
        
        transcript_doc = {
            "tenantId": tenant_id,
            "patientId": patient_id,
            "visitId": visit_id,
            "transcript": text,
            "soapNotes": result,
            "insights": {
                "allergy_triggers": result.get("patient_history", {}).get("allergies", "N/A"),
                "condition": safe_string_extract(result, "differential_diagnosis", "N/A").split('\n')[0],
                "recommendations": recommendations
            },
            "createdAt": datetime.now().isoformat()
        }
        logger.info(f"Preparing to save transcript for patient {patient_id} in tenant {tenant_id}")
        transcript_result = transcripts_collection.insert_one(transcript_doc)
        logger.info(f"Stored transcript for patient {patient_id} in tenant {tenant_id}: Inserted ID {transcript_result.inserted_id}")

        result["transcriptId"] = str(transcript_result.inserted_id)
        return jsonify({"success": True, **result}), 200
    except Exception as e:
        logger.error(f'Error processing /api/analyze request: {str(e)}')
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/login', methods=['POST', 'OPTIONS'])
def login():
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "http://127.0.0.1:8080")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response
    try:
        data = request.get_json()
        email = data.get('email')
        password = data.get('password')
        if email in SUBSCRIPTIONS and SUBSCRIPTIONS[email]["tier"] in ["Trial", "Premium", "Expired"] and password == "18June2011!":
            status = get_subscription_status(email)
            return jsonify({"success": True, "subscription": status["tier"], "trial_end": status["trial_end"], "card_last4": status["card_last4"]}), 200
        else:
            return jsonify({"success": False, "message": "Invalid email or password"}), 401
    except Exception as e:
        logger.error(f'Error processing /api/login request: {str(e)}')
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/register', methods=['POST', 'OPTIONS'])
def register():
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "http://127.0.0.1:8080")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response
    try:
        data = request.get_json()
        email = data.get('email')
        password = data.get('password')
        card_number = data.get('card_number')

        if not email or not password or not card_number or len(card_number) < 4:
            return jsonify({"success": False, "message": "Email, password, and valid card number are required"}), 400

        if email in SUBSCRIPTIONS:
            return jsonify({"success": False, "message": "User already registered"}), 400

        trial_start = datetime.now().strftime("%Y-%m-%d")
        SUBSCRIPTIONS[email] = {
            "tier": "Trial",
            "trial_start": trial_start,
            "card_last4": card_number[-4:]
        }
        status = get_subscription_status(email)
        return jsonify({"success": True, "subscription": status["tier"], "trial_end": status["trial_end"], "card_last4": status["card_last4"]}), 200
    except Exception as e:
        logger.error(f'Error processing /api/register request: {str(e)}')
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/analyze-transcript', methods=['POST', 'OPTIONS'])
def analyze_transcript_endpoint():
    logger.info("Received request for /api/analyze-transcript")
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "https://test.medoramd.ai")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response

    logger.info("Handling POST request for /api/analyze-transcript")
    tenant_id = 'default_tenant'
    patient_id = None
    visit_id = None
    email = None
    transcript = None

    try:
        data = request.get_json()
        if not data:
            logger.error("No JSON data provided in the request")
            return jsonify({"statusCode": 400, "error": "Request body must contain JSON data"}), 400

        patient_id = data.get('patientId') or data.get('patient_id')
        transcript = data.get('transcript')
        visit_id = data.get('visitId') or data.get('visit_id')
        email = data.get('email')
        tenant_id = data.get('tenantId') or data.get('tenant_id', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)

        logger.info(f"Processing transcript with data: patient_id={patient_id}, visit_id={visit_id}, tenant_id={tenant_id}, email={email}")
        
        if not all([patient_id, transcript, visit_id]):
            logger.error(f"Missing required fields: patient_id={patient_id}, transcript={'provided' if transcript else 'missing'}, visit_id={visit_id}")
            return jsonify({"statusCode": 400, "error": "patientId, transcript, and visitId are required"}), 400

        logger.info("Generating SOAP notes via xAI API")
        soap_notes = analyze_transcript(transcript)
        logger.info(f"Generated SOAP notes: {json.dumps(soap_notes, indent=2)}")

        # FIXED: Keep enhanced_recommendations as structured data
        enhanced_recommendations = soap_notes.get("enhanced_recommendations", {})
        
        # Double-check it's structured properly
        if not isinstance(enhanced_recommendations, dict):
            logger.warning("üö® ENDPOINT: Enhanced recommendations not dict, forcing structure")
            enhanced_recommendations = force_create_structured_recommendations(transcript)
            soap_notes["enhanced_recommendations"] = enhanced_recommendations
        else:
            logger.info(f"‚úÖ ENDPOINT: Enhanced recommendations properly structured with {len(enhanced_recommendations)} categories")

        logger.info(f"Storing SOAP notes in MedoraSOAPNotes for patient_id: {patient_id}, visit_id: {visit_id}, tenant_id: {tenant_id}")
        try:
            dynamodb_response = dynamodb.put_item(
                TableName='MedoraSOAPNotes',
                Item={
                    'patient_id': {'S': patient_id},
                    'visit_id': {'S': visit_id},
                    'soap_notes': {'S': json.dumps(soap_notes)},
                    'ttl': {'N': str(int(datetime.now().timestamp()) + 30 * 24 * 60 * 60)},
                    'tenantID': {'S': tenant_id}
                }
            )
            logger.info(f"Successfully stored SOAP notes in MedoraSOAPNotes for tenant {tenant_id}")
        except Exception as e:
            logger.error(f"Failed to store SOAP notes in MedoraSOAPNotes: {str(e)}")
            return jsonify({
                "statusCode": 500,
                "error": f"Failed to store SOAP notes in DynamoDB: {str(e)}"
            }), 500

        # FIXED: Store structured recommendations in MongoDB
        transcript_doc = {
            "tenantId": tenant_id,
            "patientId": patient_id,
            "visitId": visit_id,
            "transcript": transcript,
            "soapNotes": soap_notes,
            "insights": {
                "allergy_triggers": soap_notes.get("patient_history", {}).get("allergies", "N/A"),
                "condition": safe_string_extract(soap_notes, "differential_diagnosis", "N/A").split('\n')[0],
                "recommendations": enhanced_recommendations  # FIXED: Store as dict, not string
            },
            "createdAt": datetime.now().isoformat()
        }
        logger.info(f"Preparing to save transcript for patient {patient_id} with tenant {tenant_id}")
        try:
            transcript_result = transcripts_collection.insert_one(transcript_doc)
            logger.info(f"‚úÖ Stored transcript for patient {patient_id}, tenant {tenant_id}: Inserted ID {transcript_result.inserted_id}")
        except Exception as e:
            logger.error(f"Failed to store transcript in MongoDB: {str(e)}")
            return jsonify({
                "statusCode": 500,
                "error": f"Failed to store transcript in MongoDB: {str(e)}"
            }), 500

        return jsonify({
            "statusCode": 200,
            "body": {
                "soap_notes": soap_notes,
                "visit_id": visit_id,
                "tenant_id": tenant_id
            }
        }), 200

    except Exception as e:
        logger.error(f"Unexpected error in /api/analyze-transcript: {str(e)}")
        return jsonify({
            "statusCode": 500,
            "error": f"Unexpected error: {str(e)}"
        }), 500

@app.route('/api/analyze-transcript-freed', methods=['POST', 'OPTIONS'])
def analyze_transcript_freed_endpoint():
    """
    FIXED: Freed-style transcript analysis endpoint that ALSO generates structured recommendations
    """
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "https://test.medoramd.ai")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response

    try:
        data = request.get_json()
        patient_id = data.get('patientId') or data.get('patient_id')
        transcript = data.get('transcript')
        visit_id = data.get('visitId') or data.get('visit_id')
        email = data.get('email')
        tenant_id = data.get('tenantId') or data.get('tenant_id', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)

        if not all([patient_id, transcript, visit_id]):
            return jsonify({
                "statusCode": 400,
                "error": "patientId, transcript, and visitId are required"
            }), 400

        logger.info(f"üîÑ Processing Freed-style transcript analysis")
        
        # STEP 1: Use Freed-style analysis for plan_of_care
        soap_notes = analyze_transcript_freed_style(transcript)
        
        # STEP 2: FORCE generate structured recommendations
        logger.info(f"üîÑ Generating structured recommendations...")
        structured_recommendations = force_create_structured_recommendations(transcript)
        
        # STEP 3: Replace the string with structured object
        soap_notes["enhanced_recommendations"] = structured_recommendations
        
        logger.info(f"‚úÖ Added {len(structured_recommendations)} structured recommendation categories")
        logger.info(f"‚úÖ Categories: {list(structured_recommendations.keys())}")

        # Store in DynamoDB
        try:
            dynamodb_response = dynamodb.put_item(
                TableName='MedoraSOAPNotes',
                Item={
                    'patient_id': {'S': patient_id},
                    'visit_id': {'S': visit_id},
                    'soap_notes': {'S': json.dumps(soap_notes)},
                    'ttl': {'N': str(int(datetime.now().timestamp()) + 30 * 24 * 60 * 60)},
                    'tenantID': {'S': tenant_id}
                }
            )
            logger.info(f"‚úÖ Successfully stored Freed-style SOAP notes with structured recommendations")
        except Exception as e:
            logger.error(f"‚ùå Failed to store SOAP notes: {str(e)}")
            return jsonify({
                "statusCode": 500,
                "error": f"Failed to store SOAP notes: {str(e)}"
            }), 500

        # FIXED: Store structured recommendations in MongoDB insights
        transcript_doc = {
            "tenantId": tenant_id,
            "patientId": patient_id,
            "visitId": visit_id,
            "transcript": transcript,
            "soapNotes": soap_notes,
            "insights": {
                "allergy_triggers": soap_notes.get("patient_history", {}).get("allergies", "N/A"),
                "condition": safe_string_extract(soap_notes, "differential_diagnosis", "N/A").split('\n')[0],
                "recommendations": structured_recommendations  # FIXED: Store structured dict, not string
            },
            "createdAt": datetime.now().isoformat()
        }
        
        try:
            transcript_result = transcripts_collection.insert_one(transcript_doc)
            logger.info(f"‚úÖ Stored Freed-style transcript with structured recommendations: {transcript_result.inserted_id}")
        except Exception as e:
            logger.error(f"‚ùå Failed to store transcript: {str(e)}")
            return jsonify({
                "statusCode": 500,
                "error": f"Failed to store transcript: {str(e)}"
            }), 500

        return jsonify({
            "statusCode": 200,
            "body": {
                "soap_notes": soap_notes,
                "visit_id": visit_id,
                "tenant_id": tenant_id,
                "recommendations_generated": len(structured_recommendations)
            }
        }), 200

    except Exception as e:
        logger.error(f"‚ùå Unexpected error in Freed-style analysis: {str(e)}")
        return jsonify({
            "statusCode": 500,
            "error": f"Unexpected error: {str(e)}"
        }), 500

@app.route('/submit-transcript', methods=['POST', 'OPTIONS'])
def submit_transcript():
    logger.info("Received request for /submit-transcript")
    if request.method == 'OPTIONS':
        logger.info("Handling OPTIONS request for /submit-transcript")
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "https://test.medoramd.ai")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response

    logger.info("Handling POST request for /submit-transcript")
    try:
        data = request.get_json()
        patient_id = data.get('patient_id')
        transcript = data.get('transcript')
        visit_id = data.get('visit_id')
        email = data.get('email')
        tenant_id = data.get('tenantId') or data.get('tenant_id', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)

        if not all([patient_id, transcript, visit_id]):
            logger.error(f"Missing required fields: patient_id={patient_id}, transcript={'provided' if transcript else 'missing'}, visit_id={visit_id}")
            return jsonify({"error": "patient_id, transcript, and visit_id are required"}), 400

        logger.info(f"Processing transcript for patient_id: {patient_id}, visit_id: {visit_id}, tenant_id: {tenant_id}")

        logger.info("Generating SOAP notes via xAI API")
        soap_notes = analyze_transcript(transcript)
        logger.info(f"Generated SOAP notes: {json.dumps(soap_notes, indent=2)}")

        # FIXED: Keep enhanced_recommendations as structured data
        enhanced_recommendations = soap_notes.get("enhanced_recommendations", {})
        
        # Double-check it's structured properly
        if not isinstance(enhanced_recommendations, dict):
            logger.warning("üö® SUBMIT: Enhanced recommendations not dict, forcing structure")
            enhanced_recommendations = force_create_structured_recommendations(transcript)
            soap_notes["enhanced_recommendations"] = enhanced_recommendations
        else:
            logger.info(f"‚úÖ SUBMIT: Enhanced recommendations properly structured with {len(enhanced_recommendations)} categories")

        logger.info(f"Storing SOAP notes in MedoraSOAPNotes for patient_id: {patient_id}, visit_id: {visit_id}, tenant_id: {tenant_id}")
        try:
            dynamodb_response = dynamodb.put_item(
                TableName='MedoraSOAPNotes',
                Item={
                    'patient_id': {'S': patient_id},
                    'visit_id': {'S': visit_id},
                    'soap_notes': {'S': json.dumps(soap_notes)},
                    'ttl': {'N': str(int(datetime.now().timestamp()) + 30 * 24 * 60 * 60)},
                    'tenantID': {'S': tenant_id}
                }
            )
            logger.info(f"Successfully stored SOAP notes in MedoraSOAPNotes for tenant {tenant_id}")
        except Exception as e:
            logger.error(f"Failed to store SOAP notes in MedoraSOAPNotes: {str(e)}")
            return jsonify({"error": f"Failed to store SOAP notes in DynamoDB: {str(e)}"}), 500

        # FIXED: Store structured recommendations in MongoDB
        transcript_doc = {
            "tenantId": tenant_id,
            "patientId": patient_id,
            "visitId": visit_id,
            "transcript": transcript,
            "soapNotes": soap_notes,
            "insights": {
                "allergy_triggers": soap_notes.get("patient_history", {}).get("allergies", "N/A"),
                "condition": safe_string_extract(soap_notes, "differential_diagnosis", "N/A").split('\n')[0],
                "recommendations": enhanced_recommendations  # FIXED: Store as dict, not string
            },
            "createdAt": datetime.now().isoformat()
        }
        logger.info(f"Preparing to save transcript for patient {patient_id} with tenant {tenant_id}")
        try:
            transcript_result = transcripts_collection.insert_one(transcript_doc)
            logger.info(f"‚úÖ Stored transcript for patient {patient_id}, tenant {tenant_id}: Inserted ID {transcript_result.inserted_id}")
        except Exception as e:
            logger.error(f"Failed to store transcript in MongoDB: {str(e)}")
            return jsonify({"error": f"Failed to store transcript in MongoDB: {str(e)}"}), 500

        return jsonify({
            "statusCode": 200,
            "body": {
                "soap_notes": soap_notes,
                "visit_id": visit_id,
                "tenant_id": tenant_id
            }
        }), 200

    except Exception as e:
        logger.error(f"Unexpected error in /submit-transcript: {str(e)}")
        return jsonify({"error": f"Unexpected error: {str(e)}"}), 500

# Simplified insights query functions
@with_retry_and_delay(max_retries=2, delay_seconds=2)
def query_semantic_scholar(condition, retmax=2, timeout=3, rate_limit_hit=None):
    """Query Semantic Scholar for articles related to the given condition, focusing on human allergies."""
    add_api_delay(1)
    
    if len(condition) > 100:
        condition = condition.split(';')[0].split('.')[0].strip()[:100]
        logger.info(f"Simplified long condition for Semantic Scholar: {condition}")
    
    try:
        api_url = "https://api.semanticscholar.org/graph/v1/paper/search"
        
        query = f"{condition}"
        params = {
            "query": query,
            "limit": retmax,
            "fields": "title,abstract,url,year,authors,venue,citationCount"
        }
        
        headers = {}
        
        logger.debug(f"Sending Semantic Scholar request for condition '{condition}'")
        response = requests.get(api_url, params=params, headers=headers, timeout=timeout)
        
        if response.status_code == 429:
            logger.warning(f"Rate limited by Semantic Scholar for '{condition}', skipping")
            if rate_limit_hit:
                rate_limit_hit['semantic_scholar'] = True
            return []
            
        response.raise_for_status()
        
        try:
            results = response.json()
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Semantic Scholar JSON response: {str(e)}")
            return []
        
        insights = []
        
        if "data" in results:
            for paper in results["data"]:
                try:
                    title_text = paper.get("title", "N/A")
                    abstract_text = paper.get("abstract", "N/A")
                    url = paper.get("url", "#")
                    year = paper.get("year", "N/A")
                    
                    title_lower = title_text.lower() if title_text else ""
                    if any(term in title_lower for term in ['veterinary', 'animal medicine', 'pet therapy']):
                        logger.info(f"Excluding veterinary article: {title_text}")
                        continue
                    
                    authors = []
                    if "authors" in paper:
                        authors = [author.get("name", "") for author in paper["authors"]]
                    authors_text = ", ".join(authors) if authors else "N/A"
                    
                    citation_count = paper.get("citationCount", 0)
                    
                    # Simplified relevance scoring
                    relevance_score = 75.0  # Default good score
                    confidence = "Recommended"
                    
                    insight = {
                        "title": title_text,
                        "summary": abstract_text,
                        "url": url,
                        "authors": authors_text,
                        "year": year,
                        "citation_count": citation_count,
                        "source": "Semantic Scholar",
                        "confidence": confidence,
                        "relevance_score": f"{relevance_score:.1f}%",
                        "relevance_tag": f"Relevant to {condition.lower()}",
                        "raw_relevance_score": relevance_score
                    }
                    insights.append(insight)
                    
                except Exception as e:
                    logger.error(f"Error processing Semantic Scholar article: {str(e)}")
                    continue
        
        logger.info(f"Fetched {len(insights)} insights from Semantic Scholar for condition: {condition}")
        return insights
        
    except Exception as e:
        logger.error(f"Error querying Semantic Scholar for condition {condition}: {str(e)}")
        return []

@with_retry_and_delay(max_retries=2, delay_seconds=3)
def query_pubmed(condition, retmax=2, timeout=3, rate_limit_hit=None, max_attempts=2, max_rate_limit_hits=2, skip_guidelines=False):
    """Query PubMed for articles related to the given condition, focusing on human allergies."""
    add_api_delay(2)
    
    if len(condition) > 100:
        condition = condition.split(';')[0].split('.')[0].strip()[:100]
        logger.info(f"Simplified long condition to: {condition}")
    
    diagnosis_key = f"pubmed_hits_{condition}"
    if rate_limit_hit:
        rate_limit_hits = rate_limit_hit.get(diagnosis_key, 0)
        if rate_limit_hits >= max_rate_limit_hits:
            logger.warning(f"Circuit breaker triggered: Skipping PubMed query for condition '{condition}'")
            return []

    try:
        search_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
        search_params = {
            "db": "pubmed",
            "term": condition,
            "retmax": retmax,
            "sort": "relevance",
            "retmode": "json"
        }
        
        logger.debug(f"Sending PubMed search request for condition '{condition}'")
        search_response = requests.get(search_url, params=search_params, timeout=timeout)
        
        if search_response.status_code == 429:
            logger.warning(f"Rate limited by PubMed for '{condition}', skipping")
            if rate_limit_hit:
                rate_limit_hit[diagnosis_key] = rate_limit_hit.get(diagnosis_key, 0) + 1
            return []
            
        search_response.raise_for_status()
        search_data = search_response.json()
        
        id_list = search_data.get("esearchresult", {}).get("idlist", [])
        logger.debug(f"PubMed returned article IDs for condition '{condition}': {id_list}")

        if not id_list:
            logger.warning(f"No PubMed articles found for condition: {condition}")
            return []

        add_api_delay(1)
        
        fetch_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
        fetch_params = {
            "db": "pubmed",
            "id": ",".join(id_list),
            "retmode": "xml"
        }
        
        fetch_response = requests.get(fetch_url, params=fetch_params, timeout=timeout)
        
        if fetch_response.status_code == 429:
            logger.warning(f"Rate limited on PubMed fetch for '{condition}', skipping")
            return []
            
        fetch_response.raise_for_status()

        try:
            root = ET.fromstring(fetch_response.content)
        except ET.ParseError as e:
            logger.error(f"Failed to parse PubMed XML response for condition {condition}: {str(e)}")
            return []
            
        insights = []
        
        for article in root.findall(".//PubmedArticle"):
            try:
                title = article.find(".//ArticleTitle")
                title_text = title.text if title is not None else "N/A"

                abstract = article.find(".//Abstract/AbstractText")
                abstract_text = abstract.text if abstract is not None else "N/A"
                
                pubmed_id = article.find(".//PMID")
                pubmed_id_text = pubmed_id.text if pubmed_id is not None else "N/A"
                url = f"https://pubmed.ncbi.nlm.nih.gov/{pubmed_id_text}/"
                
                relevance_score = 70.0
                confidence = "Recommended"
                
                insight = {
                    "title": title_text,
                    "summary": abstract_text,
                    "pubmed_id": pubmed_id_text,
                    "url": url,
                    "confidence": confidence,
                    "relevance_score": f"{relevance_score:.1f}%",
                    "relevance_tag": f"Relevant to {condition.lower()}",
                    "source": "PubMed",
                    "authors": "N/A",
                    "year": "2024",
                    "raw_relevance_score": relevance_score
                }
                insights.append(insight)
                
            except Exception as e:
                logger.error(f"Error processing PubMed article: {str(e)}")
                continue

        logger.info(f"Fetched {len(insights)} insights from PubMed for condition: {condition}")
        return insights

    except Exception as e:
        logger.error(f"Error querying PubMed for condition {condition}: {str(e)}")
        return []

@app.route('/get-insights', methods=['GET', 'OPTIONS'])
def get_insights():
    logger.info("Handling GET request for /get-insights")
    
    start_time = time.time()
    max_processing_time = 30
    rate_limit_hit = {}
    
    try:
        if request.method == 'OPTIONS':
            logger.info("Handling OPTIONS request for /get-insights")
            response = make_response()
            response.headers.add("Access-Control-Allow-Origin", "https://test.medoramd.ai")
            response.headers.add("Access-Control-Allow-Headers", "Content-Type")
            response.headers.add("Access-Control-Allow-Methods", "GET, OPTIONS")
            return response

        patient_id = request.args.get('patient_id')
        visit_id = request.args.get('visit_id')
        email = (request.args.get('email') or
                 request.args.get('Email') or
                 request.args.get('user_email') or
                 request.args.get('userEmail'))
        tenant_id = request.args.get('tenantId', 'default_tenant')

        if not email:
            logger.warning("Email parameter missing, using fallback")
            email = "doctor@allergyaffiliates.com"

        tenant_id = validate_tenant_id(tenant_id, email)

        if not patient_id or not visit_id:
            logger.error(f"Missing required parameters: patient_id={patient_id}, visit_id={visit_id}")
            return jsonify({"error": "patient_id and visit_id are required"}), 400

        soap_notes = get_soap_notes(patient_id, visit_id, tenant_id)
        if not soap_notes:
            logger.warning(f"No SOAP notes found for patient_id: {patient_id}, visit_id: {visit_id}")
            return jsonify({
                "patient_id": patient_id,
                "visit_id": visit_id,
                "insights": []
            }), 200

        conditions = soap_notes.get("differential_diagnosis", "")
        if not conditions or conditions == "No data available":
            logger.warning(f"No differential diagnosis found")
            return jsonify({
                "patient_id": patient_id,
                "visit_id": visit_id,
                "insights": []
            }), 200

        diagnoses = []
        parts = re.split(r'[;,\n]', conditions)
        for part in parts[:3]:
            part = part.strip()
            if part and len(part) > 10:
                part = re.sub(r'^(Primary diagnosis:|Alternative diagnoses?:)', '', part, flags=re.IGNORECASE)
                part = part.strip()[:150]
                if part:
                    diagnoses.append(part)

        if not diagnoses:
            logger.warning(f"No meaningful diagnoses parsed from: {conditions}")
            return jsonify({
                "patient_id": patient_id,
                "visit_id": visit_id,
                "insights": []
            }), 200

        logger.info(f"Simplified diagnoses for searching: {diagnoses}")

        all_insights = []
        
        for diagnosis in diagnoses[:2]:
            if time.time() - start_time > max_processing_time:
                logger.warning("Timeout reached, returning partial results")
                break
                
            logger.info(f"Processing diagnosis: {diagnosis}")
            
            try:
                if time.time() - start_time < max_processing_time - 10:
                    semantic_insights = query_semantic_scholar(diagnosis, retmax=1, timeout=5, rate_limit_hit=rate_limit_hit)
                    all_insights.extend(semantic_insights)
                    time.sleep(1)
                
                if time.time() - start_time < max_processing_time - 5:
                    pubmed_insights = query_pubmed(diagnosis, retmax=1, timeout=5, rate_limit_hit=rate_limit_hit)
                    all_insights.extend(pubmed_insights)
                    time.sleep(2)
                
            except Exception as e:
                logger.error(f"Error processing diagnosis '{diagnosis}': {str(e)}")
                continue

        def get_relevance_score(insight):
            return insight.get("raw_relevance_score", 50.0)

        all_insights.sort(key=get_relevance_score, reverse=True)
        final_insights = all_insights[:5]

        for insight in final_insights:
            insight.pop("raw_relevance_score", None)

        if not final_insights:
            logger.warning(f"No insights found after processing")
            final_insights = [{
                "title": "No specific references found",
                "summary": "Consider searching medical databases manually for the diagnosed conditions. This may be due to API rate limiting or very specific/rare conditions.",
                "url": "https://pubmed.ncbi.nlm.nih.gov/",
                "source": "System Message",
                "confidence": "Info",
                "relevance_score": "N/A",
                "relevance_tag": "System guidance"
            }]

        result = {
            "patient_id": patient_id,
            "visit_id": visit_id,
            "insights": final_insights,
            "processing_time": f"{time.time() - start_time:.1f}s"
        }

        logger.info(f"Returning {len(final_insights)} insights for patient {patient_id}")
        return jsonify(result), 200

    except Exception as e:
        logger.error(f"Unexpected error in /get-insights: {str(e)}")
        return jsonify({
            "patient_id": patient_id if 'patient_id' in locals() else "unknown",
            "visit_id": visit_id if 'visit_id' in locals() else "unknown",
            "insights": [],
            "error": "Service temporarily unavailable due to API limits"
        }), 200

@app.route('/api/admin/fix-patients', methods=['POST'])
def fix_patient_tenant_ids():
    try:
        data = request.get_json()
        admin_key = data.get('admin_key')
        if admin_key != "medora_admin_key_2025":
            return jsonify({"success": False, "error": "Unauthorized"}), 401
            
        default_tenant = data.get('default_tenant', 'doctor@allergyaffiliates.com')
        
        result = patients_collection.update_many(
            {"tenantId": {"$exists": False}},
            {"$set": {"tenantId": default_tenant}}
        )
        
        transcript_result = transcripts_collection.update_many(
            {"tenantId": {"$exists": False}},
            {"$set": {"tenantId": default_tenant}}
        )
        
        visit_result = visits_collection.update_many(
            {"tenantId": {"$exists": False}},
            {"$set": {"tenantId": default_tenant}}
        )
        
        return jsonify({
            "success": True,
            "updated_patients": result.modified_count,
            "updated_transcripts": transcript_result.modified_count,
            "updated_visits": visit_result.modified_count
        }), 200
    except Exception as e:
        logger.error(f"Error fixing tenant IDs: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/push-to-ims', methods=['POST', 'OPTIONS'])
def push_to_ims():
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "*")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response

    try:
        data = request.get_json()
        patient_id = data.get('patientId')
        visit_id = data.get('visitId')
        email = data.get('email')
        tenant_id = data.get('tenantId', 'default_tenant')
        tenant_id = validate_tenant_id(tenant_id, email)

        if not patient_id or not visit_id or not email:
            logger.error(f"Missing required parameters: patientId={patient_id}, visitId={visit_id}, email={email}")
            return jsonify({"success": False, "error": "patientId, visitId, and email are required"}), 400

        logger.info(f"Attempting to push data to IMS for patient {patient_id}, visit {visit_id}, tenant {tenant_id}")
        success = push_to_fhir_server(patient_id, visit_id, tenant_id)
        if success:
            logger.info(f"Successfully pushed data to IMS FHIR server for patient {patient_id}, visit {visit_id}")
            return jsonify({"success": True, "message": "Data pushed to IMS FHIR server"}), 200
        else:
            logger.error(f"Failed to push data to IMS FHIR server for patient {patient_id}, visit {visit_id}")
            return jsonify({"success": False, "error": "Failed to push data to IMS FHIR server"}), 500
    except Exception as e:
        logger.error(f"Error in push-to-ims: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500

# ================================
# ENHANCED TESTING ENDPOINTS
# ================================

@app.route('/api/test-enhanced-recommendations-complete', methods=['POST', 'GET'])
def test_enhanced_recommendations_complete():
    """Complete test of enhanced recommendations functionality"""
    try:
        test_transcript = """
        Patient was hospitalized for 4 days just before Easter due to a class A virus and pneumonia. 
        During the hospital stay, they received a shot which helped improve their condition. 
        A pulmonary lung doctor treated them for pneumonia. Since discharge, the patient has been 
        using a breathing machine for a few days post-hospitalization and reports feeling better. 
        They continue to experience a sensation of mucus dripping down the back of their throat, 
        leading to coughing and expectoration of thick mucus.

        The patient has been on Medrol 4 mg daily, Dulera twice daily, Spiriva daily, and Flonase 
        as needed. They also use an antihistamine and a breathing machine post-hospitalization. 
        FEV1 today is 61%, indicating severe obstruction, similar to the last visit at 60%.

        Patient reports symptoms suggestive of acid reflux, including a sensation of water dripping 
        down the throat and persistent cough, which could be contributing to asthma symptoms. 
        Plan to consider biologic injections for asthma and to try Pepcid twice daily for acid reflux. 
        Additional lifestyle modifications recommended include sleeping with the head elevated, 
        eating 2-3 hours before bed, and reducing intake of coffee, tea, alcohol, spicy, and fatty foods.

        Patient education on the benefits of biologic therapy, including reduced need for oral 
        steroids and improved quality of life, is crucial; follow-up in 2 weeks to discuss further 
        and initiate paperwork if patient agrees.
        """
        
        logger.info("üß™ COMPLETE TEST: Testing enhanced analyze_transcript function")
        
        start_time = time.time()
        result = analyze_transcript(test_transcript)
        processing_time = time.time() - start_time
        
        enhanced_recs = result.get("enhanced_recommendations", {})
        
        test_results = {
            "success": True,
            "processing_time_seconds": round(processing_time, 2),
            "test_status": "COMPLETE",
            "enhanced_recommendations": {
                "type": str(type(enhanced_recs).__name__),
                "is_structured": isinstance(enhanced_recs, dict),
                "content": enhanced_recs
            }
        }
        
        if isinstance(enhanced_recs, dict):
            categories = list(enhanced_recs.keys())
            total_recommendations = sum(len(items) if isinstance(items, list) else 1 for items in enhanced_recs.values())
            
            test_results["enhanced_recommendations"].update({
                "status": "‚úÖ SUCCESS - Properly structured",
                "categories_found": categories,
                "total_categories": len(categories),
                "total_recommendations": total_recommendations,
                "recommendations_per_category": {
                    category: len(items) if isinstance(items, list) else 1
                    for category, items in enhanced_recs.items()
                },
                "sample_from_each_category": {
                    category: items[0] if isinstance(items, list) and items else str(items)
                    for category, items in enhanced_recs.items()
                }
            })
            
            logger.info(f"‚úÖ COMPLETE TEST SUCCESS: {len(categories)} categories, {total_recommendations} total recommendations")
            
        elif isinstance(enhanced_recs, list):
            test_results["enhanced_recommendations"].update({
                "status": "‚ö†Ô∏è PARTIAL FAILURE - Still a list (should be dict)",
                "list_length": len(enhanced_recs),
                "list_content": enhanced_recs,
                "fix_needed": "List-to-dict conversion failed"
            })
            
            logger.error(f"‚ö†Ô∏è COMPLETE TEST PARTIAL FAILURE: Still returning list instead of dict")
            
        elif isinstance(enhanced_recs, str):
            test_results["enhanced_recommendations"].update({
                "status": "‚ùå MAJOR FAILURE - String fallback",
                "string_content": enhanced_recs,
                "fix_needed": "AI not generating proper recommendations"
            })
            
            logger.error(f"‚ùå COMPLETE TEST MAJOR FAILURE: Falling back to string")
            
        else:
            test_results["enhanced_recommendations"].update({
                "status": f"‚ùì UNEXPECTED - Type {type(enhanced_recs)}",
                "content": str(enhanced_recs),
                "fix_needed": "Unexpected data type returned"
            })
            
            logger.error(f"‚ùì COMPLETE TEST UNEXPECTED: Type {type(enhanced_recs)}")
        
        soap_sections = {}
        for section in ["patient_history", "differential_diagnosis", "plan_of_care", "summary"]:
            if section in result:
                content = result[section]
                soap_sections[section] = {
                    "present": True,
                    "type": str(type(content).__name__),
                    "has_content": bool(content and str(content).strip() not in ["", "N/A"])
                }
            else:
                soap_sections[section] = {"present": False}
        
        test_results["soap_sections"] = soap_sections
        
        frontend_compatible = (
            isinstance(enhanced_recs, dict) and
            len(enhanced_recs) > 0 and
            all(isinstance(items, list) for items in enhanced_recs.values())
        )
        
        test_results["frontend_compatibility"] = {
            "compatible": frontend_compatible,
            "ready_for_display": frontend_compatible,
            "issues": [] if frontend_compatible else ["Enhanced recommendations not in expected dict format"]
        }
        
        return jsonify(test_results), 200
        
    except Exception as e:
        logger.error(f"üö® COMPLETE TEST ERROR: {str(e)}")
        return jsonify({
            "success": False,
            "error": str(e),
            "error_type": str(type(e).__name__),
            "traceback": traceback.format_exc()
        }), 500

@app.route('/api/test-frontend-compatibility', methods=['GET'])
def test_frontend_compatibility():
    """Test endpoint to verify frontend compatibility of enhanced AllergenIQ"""
    try:
        test_enhanced_data = {
            "symptomData": [
                {
                    "name": "Rhinorrhea",
                    "severity": "Moderate (6/10)",
                    "frequency": "Daily",
                    "context": "Worsens with pollen exposure"
                },
                {
                    "name": "Nasal congestion", 
                    "severity": 8,
                    "frequency": "Frequent",
                    "context": "Year-round symptoms"
                }
            ],
            "medicationHistory": [
                {
                    "name": "Fluticasone (Flonase)",
                    "dosage": "2 sprays twice daily",
                    "status": "Active",
                    "indication": "Allergic rhinitis",
                    "effectiveness": "Good control"
                }
            ],
            "allergenData": [
                {
                    "name": "Grass pollen",
                    "reaction": "Nasal congestion and sneezing",
                    "severity": "Moderate",
                    "avoidance_status": "Seasonal avoidance"
                }
            ],
            "summary": {
                "primaryDiagnosis": "Seasonal allergic rhinitis",
                "alternativeDiagnoses": ["Perennial allergic rhinitis"]
            }
        }
        
        compatible_data = ensure_frontend_compatibility(test_enhanced_data)
        
        test_results = {
            "compatibility_test": "PASSED",
            "frontend_expectations_met": {
                "symptom_severity_numeric": all(
                    isinstance(s.get("severity"), int) and 0 <= s.get("severity") <= 10 
                    for s in compatible_data.get("symptomData", [])
                ),
                "symptom_frequency_string": all(
                    isinstance(s.get("frequency"), str) 
                    for s in compatible_data.get("symptomData", [])
                ),
                "medication_structure_correct": all(
                    "name" in m and "dosage" in m and "status" in m
                    for m in compatible_data.get("medicationHistory", [])
                ),
                "allergen_structure_correct": all(
                    "name" in a and "reaction" in a
                    for a in compatible_data.get("allergenData", [])
                ),
                "summary_structure_correct": (
                    "primaryDiagnosis" in compatible_data.get("summary", {}) and
                    "alternativeDiagnoses" in compatible_data.get("summary", {})
                )
            },
            "original_enhanced_data": test_enhanced_data,
            "frontend_compatible_data": compatible_data,
            "frontend_javascript_test": {
                "parseInt_severity_test": [
                    f"parseInt({s.get('severity')}, 10) = {int(s.get('severity'))}"
                    for s in compatible_data.get("symptomData", [])
                ]
            }
        }
        
        return jsonify(test_results), 200
        
    except Exception as e:
        return jsonify({
            "compatibility_test": "FAILED", 
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500

# ================================
# APPLICATION STARTUP
# ================================

if __name__ == '__main__':
    try:
        patients_collection.create_index([("tenantId", 1)])
        transcripts_collection.create_index([("tenantId", 1), ("patientId", 1)])
        visits_collection.create_index([("tenantId", 1), ("patientId", 1)])
        logger.info("MongoDB indexes created successfully")
    except Exception as e:
        logger.error(f"Error creating MongoDB indexes: {str(e)}")
        
    app.run(host='0.0.0.0', port=PORT, debug=False)
